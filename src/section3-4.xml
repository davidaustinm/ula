<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-determinants"
	 xmlns:xi="http://www.w3.org/2001/XInclude">

  <title> Determinants </title>

  <introduction>
    <p> As invertibility plays a central role in this chapter, we need
    a criterion that tells us when a matrix is invertible.  
    We already know that a square matrix is invertible if and only if
    it is row equivalent to the identity matrix.  In this section, we
    will develop a second, numerical criterion that tells us when a
    square matrix is invertible.
    </p>

    <p> To begin, let's consider a <m>2\times2</m> matrix <m>A</m>
    whose columns are vectors <m>\vvec_1</m> and <m>\vvec_2</m>.  We
    have frequently drawn the vectors and studied the linear
    combinations they form using a figure such as <xref
    ref="fig-intro-dets" />.
    </p>

    <figure xml:id="fig-intro-dets">
      <sidebyside width="40%">
	<image source="images/basis-1" />
      </sidebyside>
      <caption>
	Linear combinations of two vectors <m>\vvec_1</m> and <m>\vvec_2</m> 
	form a collection of congruent parallelograms.
      </caption>
    </figure>

    <p> Notice how the linear combinations form a set of congruent
    parallelograms in the plane.  In this section, we will use the
    area of these parallelograms to define a numerical
    quantity called the determinant that tells us whether the matrix
    <m>A</m> is invertible.  
    </p>

    <sidebyside widths="60% 40%" valign="middle">
      <p> To recall, the area of parallelogram
      is found by multiplying the length of one side by the
      perpendicular distance to its parallel side.  Using the notation
      in the figure, the area of the
      parallelogram is <m>bh</m>.
      </p>
      <image source="images/parallelogram-area" />
    </sidebyside>

    <exploration label="ula-preview-3-4">
      <introduction>
        <p> We will explore the area formula in this preview
        activity.</p>
      </introduction>

      <task label="ula-preview-3-4-a">
        <statement>
	  <p> Find the area of the following parallelograms. </p>

	  <sbsgroup>
	    <sidebyside widths="3% 30% 3% 30% 3% 30%">
	      <p> 1. </p>
	      <image source="images/parallelogram-a" />
	      <p> 2. </p>
	      <image source="images/parallelogram-b" />
	      <p> 3. </p>
	      <image source="images/parallelogram-c" />
	    </sidebyside>
	    <sidebyside widths="3% 30% 3% 30% 3% 30%">
	      <p> 4. </p>
	      <image source="images/parallelogram-d" />
	      <p> 5. </p>
	      <image source="images/parallelogram-e" />
	      <p>
	      </p>
	      <p>
	      </p>
	    </sidebyside>
	  </sbsgroup>
        </statement>
        <response component="rs-preview"/>
        <solution>
	  <p> We find the following areas.
	  <ol marker="1.">
	    <li><p> A <m>1\times1</m> square has area 1. </p></li>
	    <li><p> A <m>2\times3</m> rectangle has area 6. </p></li>
	    <li><p> The square has side length <m>\sqrt{2}</m> giving
	    an area of 2. </p></li>
	    <li><p> If we consider the horizontal length as the base,
	    we see that <m>b=h=2</m> so that the area is 4. </p></li>
	    <li><p> In the same way, we can consider both the base and
	    height to be 2 so that the area is 4. </p></li>
	  </ol>
	  </p>
        </solution>
      </task>

      <task label="ula-preview-3-4-b">
        <statement>
	  <sidebyside widths="50% 40%" valign="middle">
	    <p> Explain why the area of the parallelogram formed by
	      the vectors <m>\vvec</m> and <m>\wvec_1</m> is the same as
	    that formed by <m>\vvec</m> and <m>\wvec_2</m>. </p>
	    <image source="images/area-shear" />
	  </sidebyside>
        </statement>
        <solution>
	  <p> If we consider the base to be the length of
	  <m>\vvec</m>, then the height, which is the perpendicular
	  distance to its parallel side, is the same in both
	  parallelograms. </p>
        </solution>
      </task>

    </exploration>

  </introduction>

  <subsection>
    <title> Determinants of <m>2\times2</m> matrices </title>

    <p> We will begin by defining
    the determinant of a <m>2\times2</m> matrix <m>A =
    \left[\begin{array}{rr} \vvec_1 \amp \vvec_2
    \end{array}\right]</m>.  First, however, we need to define the
    orientation of an ordered pair of vectors.  As shown in <xref
    ref="fig-det-orientation" />, an ordered pair of vectors
    <m>\vvec_1</m> and <m>\vvec_2</m> is called <em>positively</em>
    oriented if the angle, measured in the counterclockwise direction,
    from <m>\vvec_1</m> to <m>\vvec_2</m> is less than
    <m>180^\circ</m>; we say the pair is <em>negatively</em> oriented if
    it is more than <m>180^\circ</m>.
    </p>

    <figure xml:id="fig-det-orientation">
      <sidebyside width="60%">
	<image source="images/det-orientation" />
      </sidebyside>
      <caption>
	The vectors on the left are positively oriented while the ones
	on the right are negatively oriented.
      </caption>
    </figure>

    <definition>
      <statement>
	<idx> determinant </idx>
	<p> Suppose a <m>2\times2</m> matrix <m>A</m> has columns
	<m>\vvec_1</m> and <m>\vvec_2</m>.  If the pair of vectors is
	positively oriented, then the <em>determinant</em> of
	<m>A</m>, denoted <m>\det(A)</m>, is the area of the
	parallelogram formed by <m>\vvec_1</m> and <m>\vvec_2</m>.
	If the pair is negatively oriented, then <m>\det(A)</m> is
	-1 times the area of the parallelogram. </p>
      </statement>
    </definition>

    <example xml:id="example-det-identity">
      <statement>
	<p>
	  Consider the determinant of the identity matrix
	  <me>I =
	  \left[\begin{array}{rr} 1\amp 0 \\ 0 \amp 1 \\
	  \end{array}\right]
	  =
	  \left[\begin{array}{rr} \evec_1 \amp \evec_2 \\
	  \end{array}\right]
	  </me>.
	  As seen on the left of <xref ref="fig-det-identity" />,
	  the vectors <m>\vvec_1 = \evec_1</m> 
	  and <m>\vvec_2=\evec_2</m> form a positively oriented pair.
	  Since the parallelogram they form is a <m>1\times1</m> square,
	  we have <m>\det(I) = 1.</m>
	</p>

	<figure xml:id="fig-det-identity">
	  <sidebyside width="75%">
	    <image source="images/det-identity" />
	  </sidebyside>
	  <caption>
	    The determinant <m>\det(I) = 1</m>, as seen on the left.
	    On the right, we see that <m>\det(A) = -2</m>
	    where <m>A</m> is the matrix whose columns are shown.
	  </caption>
	</figure>

	<p> Now consider the matrix
	  <me>A = 
	  \left[\begin{array}{rr} -2\amp 0 \\ 0 \amp 1 \\
	  \end{array}\right]
	  =
	  \left[\begin{array}{rr} \vvec_1 \amp \vvec_2 \\
	  \end{array}\right]
	  </me>.
	  As seen on the right of <xref ref="fig-det-identity" />, the
	  vectors <m>\vvec_1</m> and <m>\vvec_2</m> form a negatively
	  oriented pair.  The parallelogram they define is a
	  <m>2\times1</m> rectangle so we have <m>\det(A) = -2</m>.
	  </p>
      </statement>
    </example>

    <activity>
      <statement>
      <p> In this activity, we will find the determinant of some
      simple <m>2\times2</m> matrices and discover some important
      properties of determinants.
      </p>

      <figure xml:id="js-det">
	<caption>
	  The geometric meaning of the determinant of a matrix.
	</caption>

	<interactive xml:id="interactive-det"
		     platform="javascript" width="100%"
		     aspect="100:80"
		     source="jslibrary/figures.js
			     jslibrary/det.js"
		     preview="preview/det-preview.png">
	  <sbsgroup>
	    <sidebyside width="60%">
	      <slate xml:id="det-sliders"
		     aspect="9:2"
		     surface="canvas" />
	    </sidebyside>
	    <sidebyside width="60%">
	      <slate xml:id="det-canvas" aspect="1:1" surface="canvas" />
	    </sidebyside>
	  </sbsgroup>
	  <instructions>
	    <p>
	      The sliders in the diagram below allow you to choose a
	      matrix <m>A=\begin{bmatrix}a \amp b \\
	      c \amp d \\
	      \end{bmatrix}</m>.  The two vectors representing the columns
	      of the matrix, along with the parallelograms they define,
	      are shown below.
	    </p>
	  </instructions>
	  <static>
	    <sidebyside width="100%">
	      <p>
		There is an interactive diagram at
		<url href="http://gvsu.edu/s/0J9"
		     visual="gvsu.edu/s/0J9"/>
		that accompanies this activity.
	      </p>
	    </sidebyside>
	    <sidebyside width="50%">
	      <image source="preview/det-preview.png"/>
	    </sidebyside>
	  </static>
	</interactive>
      </figure>

      <p> <ol marker="a.">
	<li><p>
	  Use the diagram to find the determinant of the matrix
	  <m>\left[\begin{array}{rr} -\frac12 \amp 0 \\ 0 \amp 2
	  \end{array}\right]</m>.
	  Along with <xref ref="example-det-identity"/>, what
	  does this lead you to believe is generally true about 
	  the determinant of a diagonal matrix?
	</p></li>

	<li><p> Use the diagram to find the determinant of the matrix
	<m>\left[\begin{array}{rr} 0 \amp 1 \\
	1 \amp 0 \\
	\end{array}\right]</m>.  What is the geometric effect of the
	matrix transformation defined by this matrix?
	</p></li>

	<li><p> Use the diagram to find the determinant of the matrix
	<m>\left[\begin{array}{rr} 2 \amp 1 \\
	0 \amp 1 \\
	\end{array}\right]</m>.  
	More generally, what do you notice about the determinant of any matrix
	of the form
	<m>\left[\begin{array}{rr} 2 \amp k \\
	0 \amp 1 \\
	\end{array}\right]</m>?  What does this say about the
	determinant of an upper triangular matrix?
	</p></li>

	<li><p> Use the diagram to find the determinant of any matrix
	of the form
	<m>\left[\begin{array}{rr} 2 \amp 0 \\
	k \amp 1 \\
	\end{array}\right]</m>.  What does this say about the
	determinant of a 
	lower triangular matrix?
	</p></li>

	<li><p> Use the diagram to find the determinant of the matrix
	<m>\left[\begin{array}{rr} 1 \amp -1 \\
	-2 \amp 2 \\
	\end{array}\right]</m>.   In general,
	what is the determinant of a matrix whose columns are linearly
	dependent? 
	</p></li>

	<li><p> Consider the matrices
	<me>
	  A = \left[\begin{array}{rr}
	  2 \amp 1 \\
	  2 \amp -1 \\
	  \end{array}\right],~~~
	  B = \left[\begin{array}{rr}
	  1 \amp 0 \\
	  0 \amp 2 \\
	  \end{array}\right]
	  </me>.
	  Use the diagram to find the determinants of <m>A</m>,
	  <m>B</m>, and <m>AB</m>.  What does this suggest is
	  generally true about the 
	  relationship of <m>\det(AB)</m> to <m>\det(A)</m> and
	  <m>\det(B)</m>?
	</p></li>
      </ol></p>
      </statement>

      <solution>
	<p><ol marker="a.">
	  <li><p> The determinant is <m>-1</m> because the vectors are
	  negatively oriented and the rectangle has sides of length
	  <m>\frac12</m> and <m>2</m>.  
	  The determinant of a diagonal matrix seems to be
	  the product of the diagonal entries.
	  </p></li>

	  <li><p> The matrix transformation is a reflection over the
	  line <m>y=x</m> and we see that the determinant is
	  <m>-1</m>.
	  </p></li>

	  <li><p> The determinant will continue to be <m>2</m> for any
	  value of <m>k</m>.  This illustrates the fact that the
	  determinant of an upper triangular matrix equals the product
	  of its diagonal entries.
	  </p></li>

	  <li><p> The same reasoning tells us that this determinant is
	  <m>2</m> and, in fact, the determinant of a lower triangular
	  matrix equals the product of its diagonal entries.
	  </p></li>

	  <li><p> The determinant of this matrix is <m>0</m> because
	  the parallelogram formed by the vector has no area.  This
	  suggests that the determinant of a matrix whose columns are
	  linearly dependent is <m>0</m>.  </p></li>

	  <li><p> We find that <m>\det(A) = -4</m>, <m>\det(B) = 2</m>,
	  and <m>\det(AB) = -8</m>.  This suggests that
	  <m>\det(AB) = \det(A) \det(B)</m>.
	  </p></li>
	</ol></p>
      </solution>
	  
    </activity>

    <p> Later in this section, we will learn an algebraic
    technique for computing determinants.  In the meantime, 
    we will simply note that we can define determinants for <m>n\times
    n</m> matrices by measuring the volume of a box defined by the columns
    of the matrix, even if this box resides in <m>\real^n</m> for
    some very large <m>n</m>.  
    </p>

    <sidebyside widths="60% 40%">
      <p> For example, the columns of a <m>3\times3</m> matrix
      <m>A</m> will form a parallelpiped, like the one shown here, and
      there is a means by which we can classify sets of such vectors
      as either positively or negatively oriented.  Therefore, we can
      define the determinant <m>\det(A)</m> in terms of the volume of
      the parallelpiped, but we will not worry about the details here.
      </p>
      <image source="images/det-3d" />
    </sidebyside>

    <p> Though the previous activity deals with determinants of
    <m>2\times2</m> matrices, it illustrates some important properties of
    determinants that are true more generally.  
    <ul>
      <li><p> If <m>A</m> is a triangular matrix, then <m>\det(A)</m>
      equals the product of the entries on the diagonal.  For example,
      <me>
	\det\left[\begin{array}{rr} 2 \amp 2 \\
	0 \amp 3 \\ \end{array}\right] = 2\cdot 3 = 6
	</me>, since the two parallelograms in <xref
	ref="fig-parallelogram-f" /> have equal area.
      </p>

      <figure xml:id="fig-parallelogram-f">
	<sidebyside widths="30% 30%">
	  <image source="images/parallelogram-f" />
	  <image source="images/parallelogram-b" />
	</sidebyside>
	<caption> The determinant of a triangular matrix equals the
	product of its diagonal entries.
	</caption>
      </figure>
      </li>

      <li><p> We also saw that
      <me>
	\det \left[\begin{array}{rr}
	0 \amp 1 \\
	1 \amp 0 \\
	\end{array}\right] = -1
      </me>
      because the columns form a negatively oriented pair.
      You may remember from <xref ref="subsec-triangular-invertible"/>
      that a matrix such as this is obtained by interchanging two rows
      of the identity matrix.  
      </p></li>

      <li><p> The determinant satisfies a multiplicative property,
      which says that
      <me>
	\det(AB) = \det(A)\det(B).
      </me>
      Rather than simply thinking of the
      determinant as the area of a parallelogram, we may also think
      of it as a factor by which areas are scaled under the matrix
      transformation defined by the matrix.  Applying the matrix
      transformation defined by <m>B</m> will scale area by
      <m>\det(B)</m>.  If we then compose <m>B</m> with the matrix
      transformation defined by <m>A</m>, area will scale a second
      time by the factor <m>\det(A)</m>.  The net effect is that the
      matrix transformation defined by <m>AB</m> scales area by
      <m>\det(A)\det(B)</m> so that <m>\det(AB)=\det(A)\det(B)</m>.
      </p></li>
    </ul>
    </p>

    <proposition xml:id="proposition-det-properties">
      <statement>
	<p>
	  The determinant satisfies these properties:
	  <ul>
	    <li>
	      <p>
		The determinant of a triangular matrix equals the
		product of its diagonal entries.
	      </p>
	    </li>
	    <li>
	      <p>
		If <m>P</m> is obtained by interchanging two rows of
		the identity matrix, then <m>\det(P) = -1</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\det(AB) = \det(A)\det(B)</m>.
	      </p>
	    </li>
	  </ul>
	</p>
      </statement>
    </proposition>

  </subsection>

  <subsection>
    <title> Determinants and invertibility </title>

    <p>
      Perhaps the most important property of determinants also
      appeared in the previous activity.  We saw that when the columns
      of the matrix <m>A</m> are linearly dependent, the
      parallelogram formed by those vectors folds down onto a line.
      For instance, if <m>A=\begin{bmatrix} 1 \amp 2 \\ -1 \amp -2 \\
      \end{bmatrix}</m>, then the resulting parallelogram, as shown
      in
      <xref ref="figure-linear-dep-det"/>, has zero area, which means
      that <m>\det(A)=0</m>. 
    </p>

    <figure xml:id="figure-linear-dep-det">
      <caption>
	When the columns of <m>A</m> are linearly dependent, we find
	that <m>\det(A) = 0</m>.
      </caption>
      <sidebyside width="40%">
	<image source="images/parallelogram-g"/>
      </sidebyside>
    </figure>

    <p>
      The condition that the columns of <m>A</m> are linearly
      dependent is precisely the same as the condition that <m>A</m>
      is not invertible.  This leads us to believe that <m>A</m> is
      not invertible if and only if its determinant is zero.  
      The following proposition expresses this thought.
    </p>

    <proposition xml:id="prop-invertible-det">
      <statement>
	<p> The matrix <m>A</m> is invertible if and only if <m>\det(A)
	\neq 0</m>.
	</p>
      </statement>
    </proposition>

    <p> To understand this proposition more fully, let's remember that the
    matrix <m>A</m> is invertible if and only if it is row equivalent
    to the identity matrix <m>I</m>.  We will therefore consider how
    the determinant changes when we perform row operations on a matrix.
    Along the way, we will discover an effective means to compute the
    determinant.
    </p>

    <p> In <xref ref="subsec-triangular-invertible" />, we saw how to
    describe the three row operations, scaling, interchange, and 
    replacement, using matrix multiplication.  If we perform a row
    operation on the matrix <m>A</m> to obtain the matrix <m>A'</m>,
    we would like to relate <m>\det(A)</m> and <m>\det(A')</m>.  To do
    so, 
    remember that
    <ul>
      <li> <p> Scalings are performed by multiplying a matrix <m>A</m>
      by a diagonal
      matrix, such as 
      <me>
	S = \left[\begin{array}{rrr}
	1 \amp 0 \amp 0 \\
	0 \amp 3 \amp 0 \\
	0 \amp 0 \amp 1 \\
	\end{array}\right],
      </me>
      which has the effect of multiplying the second row of <m>A</m>
      by <m>3</m> to obtain <m>A'</m>.  Since <m>S</m> is diagonal, we
      know that its determinant is the product of its diagonal entries
      so that <m>\det(S) = 3</m>.  
      This means that <m>A'=SA</m> and therefore
      <me>\det(A')=\det(S)\det(A) = 3\det(A).</me> In general, if we
      scale a row of <m>A</m> by 
      <m>k</m>, we have <m>\det(A') =
      k\det(A)</m>.  </p></li>

      <li><p> Interchanges are performed by matrices such
      as
      <me>
	P = \left[\begin{array}{rrr}
	0 \amp 1 \amp 0 \\
	1 \amp 0 \amp 0 \\
	0 \amp 0 \amp 1 \\
	\end{array}\right],
      </me>
      which has the effect of interchanging the first and second rows
      of <m>A</m>.  As we saw in <xref
      ref="proposition-det-properties"/>, <m>\det(P) = -1</m>.
      Therefore, when <m>PA=A'</m>, we have <me>\det(A')=\det(P)
      \det(A) = -\det(A).</me> In other words, <m>\det(A') =
      -\det(A)</m> when we perform an interchange.  </p></li>

      <li><p> Row replacement operations are performed by matrices
      such as
      <me>
	R = \left[\begin{array}{rrr}
	1 \amp 0 \amp 0 \\
	0 \amp 1 \amp 0 \\
	-2 \amp 0 \amp 1 \\
	\end{array}\right],
      </me>
      which multiplies the first row by <m>-2</m> and adds the result
      to the third row.  Since this is a lower triangular matrix, we
      know that the determinant is the product of the diagonal entries,
      which says that <m>\det(R) = 1</m>.  This means that when
      <m>RA = A'</m>,
      we have <m>\det(A')=\det(R)\det(A) = \det(A)</m>.  In
      other words, a row replacement does not change the determinant.
      </p></li>
    </ul>
    </p>

    <proposition xml:id="proposition-det-row-operations">
      <title> The effect of row operations on the determinant </title>
      <statement>
	<p>
	  <ul>
	    <li>
	      <p>
		If <m>A'</m> is obtained from <m>A</m> by scaling a
		row by <m>k</m>, then <m>\det(A') = k\det(A)</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		If <m>A'</m> is obtained from <m>A</m> by
		interchanging two rows, then <m>\det(A') =
		-\det(A)</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		If <m>A'</m> is obtained from <m>A</m> by performing a
		row replacement operation, then <m>\det(A') = \det(A)</m>.
	      </p>
	    </li>
	  </ul>
	</p>
      </statement>
    </proposition>
    
    <activity>
      <statement>
      <p> We will investigate the connection between the determinant
      of a matrix and its invertibility using Gaussian elimination.
      <ol marker="a.">
	<li><p> Consider the two upper triangular matrices
	<me>
	  U_1 =
	  \left[\begin{array}{rrr}
	  1 \amp -1 \amp 2 \\
	  0 \amp 2 \amp 4 \\
	  0 \amp 0 \amp -2 \\
	  \end{array}\right],~~~
	  U_2 =
	  \left[\begin{array}{rrr}
	  1 \amp -1 \amp 2 \\
	  0 \amp 2 \amp 4 \\
	  0 \amp 0 \amp 0 \\
	  \end{array}\right].
	</me>
	Remembering <xref
	ref="proposition-triangular-invertibility"/>, 
	which of the matrices <m>U_1</m> and <m>U_2</m> are
	invertible?  What are the determinants <m>\det(U_1)</m> and
	<m>\det(U_2)</m>? 
	</p></li>

	<li><p> Explain why an upper triangular matrix is invertible
	if and only if its determinant is not zero.
	</p></li>

	<li><p> 
	  Let's now consider the matrix
	  <me>
	    A = 
	    \left[\begin{array}{rrr}
	    1 \amp -1 \amp 2 \\
	    -2 \amp 2 \amp -6 \\
	    3 \amp -1 \amp 10 \\
	    \end{array}\right]
	  </me> and begin the Gaussian elimination process
	  with a row replacement operation
	  <me>
	    A = 
	    \left[\begin{array}{rrr}
	    1 \amp -1 \amp 2 \\
	    -2 \amp 2 \amp -6 \\
	    3 \amp -1 \amp 10 \\
	    \end{array}\right]
	    \sim
	    \left[\begin{array}{rrr}
	    1 \amp -1 \amp 2 \\
	    0 \amp 0 \amp -2 \\
	    3 \amp -1 \amp 10 \\
	    \end{array}\right]
	    = A_1
	    </me>.
	    What is the relationship between <m>\det(A)</m> and
	    <m>\det(A_1)</m>?
	</p></li>

	<li><p> Next we perform another row replacement operation:
	<me>
	  A_1=
	\left[\begin{array}{rrr}
	1 \amp -1 \amp 2 \\
	0 \amp 0 \amp -2 \\
	3 \amp -1 \amp 10 \\
	\end{array}\right]
	\sim
	\left[\begin{array}{rrr}
	1 \amp -1 \amp 2 \\
	0 \amp 0 \amp -2 \\
	0 \amp 2 \amp 4 \\
	\end{array}\right]
	= A_2
	</me>.
	What is the relationship between <m>\det(A)</m> and
	<m>\det(A_2)</m>? 
	</p></li>

	<li><p> Finally, we perform an interchange:
	<me>
	  A_2 =
	  \left[\begin{array}{rrr}
	1 \amp -1 \amp 2 \\
	0 \amp 0 \amp -2 \\
	0 \amp 2 \amp 4 \\
	\end{array}\right]
	\sim
	  \left[\begin{array}{rrr}
	  1 \amp -1 \amp 2 \\
	  0 \amp 2 \amp 4 \\
	  0 \amp 0 \amp -2 \\
	  \end{array}\right]
	  = U
	</me>
	to arrive at an upper triangular matrix <m>U</m>.  What is the
	relationship between <m>\det(A)</m> and <m>\det(U)</m>?
	</p></li>

	<li><p> Since <m>U</m> is upper
	triangular, we can compute its determinant, which allows us to
	find <m>\det(A)</m>.  What is <m>\det(A)</m>?  Is <m>A</m>
	invertible?
	</p></li>

	<li><p> Now consider the matrix
	<me>
	  A = 
	  \left[\begin{array}{rrr}
	  1 \amp -1 \amp 3 \\
	  0 \amp 2 \amp -2 \\
	  2 \amp 1 \amp 3 \\
	  \end{array}\right].
	</me>
	Perform a sequence of row operations to find an upper
	triangular matrix <m>U</m> that is row equivalent to
	<m>A</m>.  Use this to determine <m>\det(A)</m> and whether
	<m>A</m> is invertible.
	</p></li>

	<li><p> Suppose we apply a sequence of row operations on a
	matrix <m>A</m> to obtain <m>A'</m>.  Explain why <m>\det(A)
	\neq 0</m> if and only if <m>\det(A') \neq 0</m>.
	</p></li>

	<li><p> Explain why an <m>n\times n</m> matrix
	<m>A</m> is invertible if and only if <m>\det(A) \neq 0</m>.
	</p></li>

      </ol></p>
      </statement>

      <solution>
	<p><ol marker="a.">
	  <li><p> The matrix <m>U_1</m> is invertible because we see
	  there is a pivot position in every row and column.  The
	  matrix <m>U_2</m>, however, is not invertible because there
	  is not a pivot position in the third row. Also, <m>\det(U_1)=-4</m>
	  and <m>\det(U_2)=0</m>.
	  </p></li>

	  <li><p> The determinant of an upper triangular matrix equals
	  the product of its diagonal entries.  Consequently, if the
	  determinant of an upper triangular matrix is not zero, then
	  each of its diagonal entries must be nonzero.  In this case,
	  there is a pivot position in every row and every column so
	  that the matrix is invertible.  </p></li>

	  <li><p> Row replacement operations do not change the
	  determinant so <m>\det(A) = \det(A_1)</m>.
	  </p></li>

	  <li><p> In the same way, <m>\det(A) =
	  \det(A_2)</m>. </p></li> 

	  <li><p> Interchanges change the sign of the determinant so
	  <m>\det(A) = -\det(U)</m>.
	  </p></li>

	  <li><p> The determinant <m>\det(U) = -4</m> since it is the
	  product of the diagonal entries of <m>U</m>.  This means
	  that <m>\det(A) = 4</m>.  We see that <m>A</m> is invertible
	  because <m>U</m>, which has a pivot position in every row
	  and every column, is invertible.
	  </p></li>

	  <li><p> Beginning with a row replacement operation, we
	  arrive at
	  <me>A_1=\left[\begin{array}{rrr}
	  1 \amp - 1 \amp 3 \\
	  0 \amp 2 \amp -2 \\
	  0 \amp -3 \amp 3 \\
	  \end{array}\right]</me>.  We next scale the second row by
	  <m>\frac12</m> to obtain
	  <me>A_2=\left[\begin{array}{rrr}
	  1 \amp - 1 \amp 3 \\
	  0 \amp 1 \amp -1 \\
	  0 \amp -3 \amp 3 \\
	  \end{array}\right]</me>.  Another row replacement operation
	  gives
	  <me>A_3=\left[\begin{array}{rrr}
	  1 \amp - 1 \amp 3 \\
	  0 \amp 1 \amp -1 \\
	  0 \amp 0 \amp 0 \\
	  \end{array}\right]</me>.  Putting these operations together,
	  we see that <m>\det(A) = 2\det(U) = 0</m>.  In this case,
	  <m>A</m> is not invertible because <m>U</m>, which has a row
	  without a pivot position, is not invertible.
	  </p></li>

	  <li><p> Performing one of the three row operations either
	  leaves the determinant unchanged (row replacement), changes
	  its sign (interchange), or multiplies it by a nonzero number
	  (scaling).  Therefore, if we begin with a matrix whose
	  determinant is not zero, the determinant remains nonzero
	  after any row operation is applied.
	  </p></li>

	  <li><p> If we apply a sequence of row operations to <m>A</m>
	  to find a
	  row equivalent matrix <m>U</m> that is upper triangular, we
	  know that <m>\det(A)\neq0</m> if and only if <m>\det(U) \neq 0</m>.
	  We also know that <m>A</m> is invertible if and only if
	  <m>U</m> is invertible.  Putting these facts together, we
	  conclude that <m>\det(A)\neq 0</m> if and only if <m>A</m> is
	  invertible. </p></li>

	</ol></p>
      </solution>
	    
    </activity>

    <p> As seen in this activity, row operations can be used to
    compute the determinant of a matrix.  More specifically, 
    applying the forward substitution phase of Gaussian
    elimination to the matrix <m>A</m> leads us to an upper triangular
    matrix <m>U</m> so that <m>A\sim U</m>.
    </p>

    <p>
      We know that <m>U</m> is
      invertible when all of its diagonal entries are nonzero.  We also
      know that <m>\det(U)\neq 0</m> under the same condition.  This
      tells us <m>U</m> is invertible if and only if <m>\det(U) \neq 0</m>.
    </p>

    <p>
      Now if <m>\det(A)\neq 0</m>, we also have <m>\det(U)\neq 0</m>
      since applying a sequence of row operations to <m>A</m> only
      multiplies the determinant by a nonzero number.  It then follows
      that <m>U</m> is invertible so <m>U\sim I</m>.  Therefore, we
      also know that <m>A\sim I</m> and so <m>A</m> must also be
      invertible.
    </p>

    <p>
      This explains <xref ref="prop-invertible-det"/> and so we know
      that <m>A</m> is invertible
      if and only if <m>\det(A)\neq 0</m>.
    </p>

    <p>
      Finally, notice that if <m>A</m> is invertible, we have
      <m>A^{-1}A = I</m>, 
      which tells us that
      <me>
	\det(A^{-1}A) = \det(A^{-1})\det(A) = 1.
      </me>
      Therefore, <m>\det(A^{-1}) = 1/\det(A)</m>.
    </p>

    <proposition>
      <statement>
	<p>
	  If <m>A</m> is an invertible matrix, then
	  <m>\det(A^{-1}) = 1/\det(A)</m>.
	</p>
      </statement>
    </proposition>
	    
  </subsection>

  <subsection>
    <title> Cofactor expansions </title>

    <p> We now have a technique for computing the determinant of a
    matrix using row operations.  There is another way to compute
    determinants, using what are called <em>cofactor expansions</em>,
    that will be important for us in the next chapter. 
    We will describe this method here.
    </p>

    <p> To begin, the determinant of a <m>2\times2</m> matrix is
    <me>
      \det\left[\begin{array}{rr}
      a \amp b \\
      c \amp d \\
      \end{array}\right]
      =
      ad-bc
    </me>.  With a little bit of work, it can be shown that this
    number is the same as the signed area of the parallelogram we
    introduced earlier.
    </p>

    <p> Using a cofactor expansion to find the determinant of a more
    general <m>n\times n</m> matrix is a little more work so we will
    demonstrate it with an example.
    </p>

    <example>
      <statement>
	<p> We illustrate how to use a cofactor expansion to find the
	determinant of <m>A</m> where
	<me>
	  A = 
	  \left[\begin{array}{rrr}
	  1 \amp -1 \amp 2 \\
	  -2 \amp 2 \amp -6 \\
	  3 \amp -1 \amp 10 \\
	  \end{array}\right].
	</me>
	</p>

	<p> To begin, we choose one row or column.  It doesn't matter
	which we choose because the result will be the same in any
	case.  Here, we choose the second row
	<me>
	  \left[\begin{array}{rrr}
	  \lgray{1} \amp \lgray{-1} \amp \lgray{2} \\
	  -2 \amp 2 \amp -6 \\
	  \lgray{3} \amp \lgray{-1} \amp \lgray{10} \\
	  \end{array}\right]
	</me>.
	</p>

	<p> The determinant will be found by creating a sum of terms,
	one for each entry in the row we have chosen.  For each entry
	in the row, we form its term by
	multiplying
	<ul>
	  <li><p> <m>(-1)^{i+j}</m> where <m>i</m> and <m>j</m> are
	  the row and column numbers, respectively, of the
	  entry, </p></li>
	  <li><p> the entry itself, and </p></li>
	  <li><p> the determinant of the entries left over when we
	  have crossed out the row and column containing the
	  entry. </p> </li>
	</ul>
	</p>

	<p> Since we are computing the determinant of this matrix
	<me>
	  \left[\begin{array}{rrr}
	  \gray{1} \amp \gray{-1} \amp \gray{2} \\
	  -2 \amp 2 \amp -6 \\
	  \gray{3} \amp \gray{-1} \amp \gray{10} \\
	  \end{array}\right]
	</me>
	using the second row, the entry in the first column of this
	row is <m>-2</m>.  Let's see 
	how to form the term from this entry.
	</p>

	<p> The term itself is <m>-2</m>, and the matrix that is left
	over when we cross out the second row and first column is
	<me>
	  \left[\begin{array}{rrr}
	  \gray{1} \amp {-1} \amp {2} \\
	  \gray{-2} \amp \gray{2} \amp \gray{-6} \\
	  \gray{3} \amp {-1} \amp {10} \\
	  \end{array}\right]
	</me>
	whose determinant is
	<me>
	  \det\left[\begin{array}{rr}
	  -1 \amp 2 \\
	  -1 \amp 10 \\
	  \end{array}\right] =
	  -1(10) - 2 (-1) = -8
	</me>.
	Since this entry is in the second row and first column, the
	term we construct is
	<m> (-1)^{2+1}(-2)(-8) = -16
	</m>.
	</p>

	<p> Putting this together, we find the determinant to be
	<me>
	  \begin{aligned}
	  \left[\begin{array}{rrr}
	  {1} \amp {-1} \amp {2} \\
	  -2 \amp {2} \amp {-6} \\
	  {3} \amp {-1} \amp {10} \\
	  \end{array}\right] 
	  {}={}
	  \amp
	  (-1)^{2+1}(-2)\det\left[\begin{array}{rr}
	  -1 \amp 2 \\
	  -1 \amp 10 \\
	  \end{array}\right] \\
	  \amp
	  {}+{}
	  (-1)^{2+2}(2)\det\left[\begin{array}{rr}
	  1 \amp 2 \\
	  3 \amp 10 \\
	  \end{array}\right] \\
	  \amp
	  {}+{}
	  (-1)^{2+3}(-6)\det\left[\begin{array}{rr}
	  -1 \amp -1 \\
	  3 \amp -1 \\
	  \end{array}\right] \\
	  \\
	  {}={}
	  \amp
	  (-1)(-2)(-1(10)-2(-1)) \\
	  \amp + (1)(2)(1(10)-2(3)) \\
	  \amp + (-1)(-6)((-1)(-1)-(-1)3) \\ \\
	  {}={}
	  \amp
	  -16 + 8 + 12 \\
	  {}={}
	  \amp
	  4 \\

	  \end{aligned}
	</me>.
	Notice that this agrees with the determinant that we found for
	this matrix using row operations in the last activity.
	</p>	  
	  
      </statement>
    </example>

    <activity>
      <statement>
      <p> We will explore cofactor expansions through some
      examples.
      <ol marker="a.">
	<li><p> Using a cofactor expansion, show that the determinant
	of the following matrix 
	<me> \det
	  \left[\begin{array}{rrr}
	  2 \amp 0 \amp -1 \\
	  3 \amp 1 \amp 2 \\
	  -2 \amp 4 \amp -3 \\
	  \end{array}\right] = -36
	</me>.  Remember that you can choose any row or column to
	create the expansion, but the choice of a particular row or
	column may simplify 
	the computation.
	</p></li>

	<li><p> Use a cofactor expansion to find the determinant of
	<me>
	  \left[\begin{array}{rrrr}
	  -3 \amp 0 \amp 0 \amp 0 \\
	  4 \amp 1 \amp 0  \amp 0 \\
	  -1 \amp 4 \amp -4 \amp 0\\
	  0 \amp 3 \amp 2 \amp 3 \\
	  \end{array}\right]
	</me>.  Explain how the cofactor expansion technique shows
	that the determinant of a triangular matrix is equal to the
	product of its diagonal entries.
	</p></li>

	<li><p> Use a cofactor expansion to determine whether the
	following vectors form a basis of <m>\real^3</m>:
	<me>
	  \threevec{2}{-1}{-2},
	  \threevec{1}{-1}{2},
	  \threevec{1}{0}{-4}
	</me>.
	</p></li>
	
	<li><p> Sage will compute the determinant of a matrix <c>A</c>
	with the command <c>A.det()</c>.  Use Sage to find the
	determinant of the matrix
	<me>
	  \left[\begin{array}{rrrr}
	  2 \amp 1 \amp -2 \amp -3 \\
	  3 \amp 0 \amp -1  \amp -2 \\
	  -3 \amp 4 \amp 1 \amp 2\\
	  1 \amp 3 \amp 3 \amp -1 \\
	  \end{array}\right]
	</me>.
	<sage>
	  <input>
	  </input>
	</sage>
	  
	</p></li>

      </ol></p>
      </statement>

      <solution>
	<p><ol marker="a.">
	  <li><p> We will using a cofactor expanion along the first
	  row so that
	  <me>
	    \begin{array}{rl}
	    \det\left[\begin{array}{rrr}
	    2 \amp 0 \amp -1 \\
	    3 \amp 1 \amp 2 \\
	    -2 \amp 4 \amp -3 \\
	    \end{array}\right]
	    = \amp
	    (-1)^{1+1}\cdot 2 \det\left[\begin{array}{rr}
	    1 \amp 2 \\
	    4 \amp -3 \\
	    \end{array}\right] \\
	    \amp 
	    + (-1)^{1+3}\cdot (-1) \det\left[\begin{array}{rr}
	    3 \amp 1 \\
	    -2 \amp 4 \\
	    \end{array}\right] \\
	    = \amp
	    2(-11) - 14 = -36\text{.}
	    \end{array}
	  </me>
	  </p></li>

	  <li><p> Expanding along the first row gives
	  <me>
	    \begin{array}{rl}
	    \det
	    \left[\begin{array}{rrrr}
	    -3 \amp 0 \amp 0 \amp 0 \\
	    4 \amp 1 \amp 0  \amp 0 \\
	    -1 \amp 4 \amp -4 \amp 0\\
	    0 \amp 3 \amp 2 \amp 3 \\
	    \end{array}\right] \amp
	    = 3\det
	    \left[\begin{array}{rrr}
	    1 \amp 0  \amp 0 \\
	    4 \amp -4 \amp 0\\
	    3 \amp 2 \amp 3 \\
	    \end{array}\right] \\
	    \amp
	    =-3(1)\det
	    \left[\begin{array}{rr}
	    -4 \amp 0 \\
	    2 \amp 3 \\
	    \end{array}\right] \\
	    \amp
	    =-3(1)(-4)(3) = 36\text{.}
	    \end{array}
	  </me>
	  </p></li>

	  <li><p> We form the matrix <m>A</m> whose columns are the
	  three given vectors.  Expanding along either the second row or third
	  column to take advantage of the zero in the <m>(2,3)</m>
	  entry, we see that <m>\det(A) = 0</m>, which means that
	  <m>A</m> is not invertible.  Therefore, the vectors do not
	  form a basis for <m>\real^3</m>.
	  </p></li>

	  <li><p> Sage tells us that <m>\det(A) = 72</m>.
	  </p></li>
	</ol></p>
      </solution>
	    
    </activity>

  </subsection>

  <subsection>
    <title> Summary </title>

    <p> In this section, we associated a numerical quantity, the
    determinant, to a square matrix and showed how it tells us whether
    the matrix is invertible.

    <ul>
      <li><p> The determinant of a matrix has a geometric
      interpretation.  In particular, when
      <m>n=2</m>, the determinant is the signed area of
      the parallelogram formed by the two columns of the matrix.
      </p></li>

      <li><p> The determinant satisfies many properties.  For instance, 
      <m>\det(AB) = \det(A) \det(B)</m> and
      the determinant of a triangular matrix is equal to the
      product of its diagonal entries. </p></li>

      <li><p> These properties helped us compute the determinant of a
      matrix using row operations.  This also led to the important
      observation that the determinant of a matrix is nonzero if and
      only if the matrix is invertible. </p></li>

      <li><p> Finally, we learned how to compute the determinant of a
      matrix using cofactor expansions, which will be
      a valuable tool
      for us in the next chapter. </p></li>
    </ul></p>

    <p> We have seen three ways to compute the
    determinant: by interpreting the determinant as a signed area or
    volume; by applying appropriate row operations; and by using a
    cofactor expansion.  It's worth spending a moment to think about
    the relative merits of these approaches.
    </p>

    <p> The geometric definition of the determinant tells us that the
    determinant is measuring a natural geometric quantity, an insight
    that does not easily come through the other two approaches.  The
    intuition we gain by thinking about the determinant geometrically
    makes it seem reasonable that the determinant should be zero for
    matrices that are not invertible: if the columns are linearly
    dependent, the vectors cannot create a positive volume.
    </p>

    <p> Approaching the determinant through row operations provides an
    effective means of computing the determinant.  In fact, this is
    what most computer programs do behind the scenes when they
    compute a determinant.  This approach is also a useful theoretical
    tool for explaining why the determinant tells us whether a matrix
    is invertible.
    </p>

    <p> The cofactor expansion method will be useful to us in the next
    chapter when we look at eigenvalues and eigenvectors.  It is not,
    however, a practical way to compute a determinant.  To see why,
    consider the fact that the determinant of a <m>2\times2</m>
    matrix, written as <m>ad-bc</m>,
    requires us to compute two terms, <m>ad</m> and <m>bc</m>.  To
    compute the determinant of a <m>3\times3</m> matrix, we need to
    compute three <m>2\times2</m> determinants, which involves
    <m>3\cdot 2 = 6</m> terms.  For a <m>4\times4</m> matrix, we need
    to compute four <m>3\times3</m> determinants, which produces
    <m>4\cdot3\cdot2 = 24</m> terms.  Continuing in this way, we see
    that the cofactor expansion of a <m>10\times10</m> matrix would
    involve <m>10\cdot9\cdot8\ldots3\cdot2 = 10! = 3628800</m> terms.
    </p>

    <p> By contrast, we have seen that the number of steps required to
    perform Gaussian elimination on an <m>n\times n</m> matrix is
    proportional to <m>n^3</m>.  When <m>n=10</m>, we have <m>n^3 =
    1000</m>, which points to the fact that finding the determinant
    using Gaussian elimination is considerably less work.
    </p>

  </subsection>
  
  <xi:include href="exercises/exercises3-4.xml" />

</section>
