<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-eigen-intro"
	 xmlns:xi="http://www.w3.org/2001/XInclude">

  <title> An introduction to eigenvalues and eigenvectors </title>

  <introduction>
    <p> This section introduces the concept of eigenvalues and
    eigenvectors and offers an example that motivates our interest in
    them.  The point here is to develop an intuitive understanding of
    eigenvalues and eigenvectors and explain how they can be used to
    simplify some problems that we have previously encountered.
    In the rest of this chapter, we will develop this concept
    into a richer theory and illustrate its use with more meaningful
    examples. </p>

    <exploration label="ula-preview-4-1">
      <introduction>
      <p> Before we introduce the definition of eigenvectors and
      eigenvalues, it will be helpful to remember some ideas we have
      seen previously.</p>
      </introduction>

      <task label="ula-preview-4-1-a">
        <statement>
	  <sidebyside widths="50% 45%">
	  <p> Suppose that <m>\vvec</m> is the vector shown in the
	  figure.  Sketch the vector <m>2\vvec</m> and the vector
	  <m>-\vvec</m>.
	  </p>
	  <image source="images/eigen-intro-vec">
            <shortdescription>
              A two dimensional vector and coordinate grid.
            </shortdescription>
            <description>
              <p>A <m>1\times1</m> standard coordinate grid with a
              vector <m>\vvec=\twovec12</m>.</p>
            </description>
          </image>
	  </sidebyside>
          <p component="rs-preview">You will be prompted to upload a
          scan of your sketch in part (b).</p>
        </statement>
        <solution>
	  <p>
	    The vectors are as shown.
	    <sidebyside width="40%">
	      <image source="images/ex-eigen-intro-vec" />
	    </sidebyside>
	  </p>
        </solution>
      </task>

      <task label="ula-preview-4-1-b" attachment="yes">
        <statement>
	  <p> State the geometric effect that scalar multiplication
	  has on the vector <m>\vvec</m>.  Then sketch all the vectors
	  of the form <m>\lambda \vvec</m> where <m>\lambda</m> is a scalar.
	  </p>
          <p component="rs-preview">Scan and upload your
          sketch below.</p>
        </statement>
        <response component="rs-preview"/>
        <solution>
	  <p> Scalar multiplication has the effect of stretching
	  and possibly flipping <m>\vvec</m> along the line defined by
	  <m>\vvec</m>. </p>
        </solution>
      </task>

      <task label="ula-preview-4-1-c">
        <statement>
	  <p> State the geometric effect of the matrix
	  transformation defined by
	  <me>
	    \left[\begin{array}{rr}
	    3 \amp 0 \\
	    0 \amp -1 \\
	    \end{array}\right]
	    </me>.
	  </p>
        </statement>
        <response component="rs-preview"/>
        <solution>
	  <p> This matrix transformation stretches vectors by a
	  factor of <m>3</m> in the horizontal direction and flips
	  vectors vertically.
	  </p>
        </solution>
      </task>

      <task label="ula-preview-4-1-d">
        <statement>
	  <p> Suppose that <m>A</m> is a <m>2\times 2</m>
	  matrix and that <m>\vvec_1</m> and <m>\vvec_2</m> are vectors
	  such that
	  <me>
            A\vvec_1 = 3 \vvec_1, \qquad A\vvec_2 = -\vvec_2
	  </me>.
	  Use the linearity of matrix multiplication to express the
	  following vectors in terms of <m>\vvec_1</m> and
	  <m>\vvec_2</m>.
	  <ol marker="1.">
	    <li><p> <m>A(4\vvec_1)</m>. </p></li>
	    <li><p> <m>A(\vvec_1 + \vvec_2)</m>. </p></li>
	    <li><p> <m>A(4\vvec_1 -3\vvec_2)</m>. </p></li>
	    <li><p> <m>A^2\vvec_1</m>. </p></li>
	    <li><p> <m>A^2(4\vvec_1 - 3\vvec_2)</m>. </p></li>
	    <li><p> <m>A^4\vvec_1</m>. </p></li>
	  </ol></p>
        </statement>
        <response component="rs-preview"/>

        <solution>
	  <p> Applying linearity, we see that
	  <ol marker="1.">
	    <li><p> <m>A(4\vvec_1) = 4A\vvec_1 =
	    12\vvec_1</m>. </p></li>
	    <li><p> <m>A(\vvec_1+\vvec_2) = A\vvec_1 + A\vvec_2 =
	    3\vvec_1 - \vvec_2</m>. </p></li>
	    <li><p> <m>A(4\vvec_1-3\vvec_2) = 4A\vvec_1 -3A\vvec_2 =
	    12\vvec_1 + 3\vvec_2</m>. </p></li>
	    <li><p> <m>A^2\vvec_1 = A(3\vvec_1) =
	    9\vvec_1</m>. </p></li>
	    <li><p> <m>A^2(4\vvec_1-3\vvec_2) = A(12\vvec_1 +3\vvec_2) =
	    36\vvec_1 - 3\vvec_2</m>. </p></li>
	    <li><p> <m>A^4\vvec_1 = 3^4\vvec_1 =
	    81\vvec_1</m>. </p></li>
	  </ol>
	  </p>
        </solution>
      </task>

      <task component="rs-preview">
        <query label="ula-preview-4-1-poll" visibility="instructor">
          <statement>
            <p>I feel confident with the material in this activity.</p>
          </statement>
          <choices>
            <choice><p>Strongly Agree</p></choice>
            <choice><p>Agree</p></choice>
            <choice><p>Neutral</p></choice>
            <choice><p>Disagree</p></choice>
            <choice><p>Strongly Disagree</p></choice>
          </choices>
        </query>
      </task>

      <task component="rs-preview"
            label="ula-preview-4-1-what-else">
        <statement>
          <p>What would you need to know to feel
          more confident about this material?</p>
        </statement>
        <response/>
      </task>

    </exploration>

  </introduction>

  <subsection>
    <title> A few examples </title>

    <p> We will now introduce the definition of eigenvalues and
    eigenvectors and then look at a few simple examples.</p> 

    <definition xml:id="definition-eigenvectors">
      <statement>
	<idx> eigenvalue </idx>
	<idx> eigenvector </idx>
	<p> Given a square <m>n\times n</m> matrix <m>A</m>, we say
	that a nonzero vector <m>\vvec</m> is an <em>eigenvector</em>
	of <m>A</m> if there is a scalar <m>\lambda</m> such that
	<me>
	  A\vvec = \lambda \vvec
	</me>.
	The scalar <m>\lambda</m> is called the <em>eigenvalue</em>
	associated to the eigenvector <m>\vvec</m>.
	</p>
      </statement>
    </definition>

    <p> At first glance, there is a lot going on in this definition so
    let's look at an example.
    </p>

    <example>
      <statement>
	<p> Consider the matrix
	<m> A = \left[\begin{array}{rr}
	7 \amp 6 \\
	6 \amp -2 \\
	\end{array}\right]
	</m>
	and the vector <m>\vvec=\twovec{2}{1}</m>.  We find that
	<me>
	  A\vvec = \left[\begin{array}{rr}
	  7 \amp 6 \\
	  6 \amp -2 \\
	  \end{array}\right]
	  \twovec{2}{1}
	  =
	  \twovec{20}{10}
	  =10\twovec{2}{1}
	  =10\vvec
	</me>.
	In other words, <m>A\vvec = 10\vvec</m>, which says that
	<m>\vvec</m> is an eigenvector of the matrix <m>A</m> with
	associated eigenvalue <m>\lambda = 10</m>.
	</p>

	<p> Similarly, if <m>\wvec = \twovec{-1}{2}</m>, we find that
	<me>
	  A\wvec = \left[\begin{array}{rr}
	  7 \amp 6 \\
	  6 \amp -2 \\
	  \end{array}\right]
	  \twovec{-1}{2}
	  =
	  \twovec{5}{-10}
	  =-5\twovec{-1}{2}
	  =-5\wvec
	</me>.
	Here again, we have <m>A\wvec = -5\wvec</m> showing that
	<m>\wvec</m> is an eigenvector of <m>A</m> with associated
	eigenvalue <m>\lambda=-5</m>.
	</p>
      </statement>
    </example>

    <activity xml:id="activity-eigen-geom">
      <statement>
      <p> This definition has an important geometric interpretation
      that we will investigate here.
      <ol marker="a.">
	<li><p> Suppose that <m>\vvec</m> is a nonzero vector and
	that <m>\lambda</m> is a scalar.  What is the geometric
	relationship between <m>\vvec</m> and <m>\lambda\vvec</m>?
	</p></li>

	<li><p> Let's now consider the eigenvector condition:
	<m>A\vvec = \lambda\vvec</m>.  Here we have two vectors,
	<m>\vvec</m> and <m>A\vvec</m>.  If <m>A\vvec =
	\lambda\vvec</m>, what is the geometric relationship between
	<m>\vvec</m> and <m>A\vvec</m>?
	</p></li>

	<li>
	<figure xml:id="js-eigen">
	  <caption>
	    A geometric interpretation of the eigenvalue-eigenvector
	    condition <m>A\vvec = \lambda\vvec</m> .
	  </caption>
	  
	  <interactive xml:id="interactive-eigen"
		       platform="javascript" width="100%"
		       aspect="36:34"
		       source="jslibrary/figures.js
			       jslibrary/eigenvectors.js"
		       preview="preview/eigenvectors-preview.png">
            <shortdescription>
              An interactive diagram for exploring eigenvectors.
            </shortdescription>
            <description>
              <p>An interactive diagram in which the reader can select
              a <m>2\times2</m> matrix <m>A</m> using a set of sliders
              appearing in a <m>2\times2</m> array across the top.
              Below that is a <m>1\times1</m> standard coordinate grid
              and coordinate axes along with a vector <m>\vvec</m>
              that can be moved by clicking and dragging.  The vector
              <m>A\vvec</m> is also shown.</p>
            </description>
	    <sbsgroup>
	      <sidebyside width="75%">
		<slate xml:id="eigenvectors-sliders"
		       aspect="9:2"
		       surface="canvas" />
	      </sidebyside>
	      <sidebyside width="75%">
		<slate xml:id="eigenvectors-canvas"
		       aspect="1:1"
		       surface="canvas" />
	      </sidebyside>
	    </sbsgroup>
	    <instructions>
	      <p>
		The sliders in the diagram below allow you to choose a
		matrix <m>A = \begin{bmatrix} a \amp b \\ c \amp d
		\end{bmatrix}</m>.  The vector <m>\vvec</m>, shaded
		red, may be moved by clicking in the head of the
		vector.  The vector <m>A\vvec</m> is then shown in
		outline.
	      </p>
	    </instructions>
	    <static>
	      <sidebyside width="100%">
		<p>
		  There is an interactive diagram, available at
		  <url href="http://gvsu.edu/s/0Ja"
		       visual="gvsu.edu/s/0Ja"/>,
		  that accompanies this activity.
		</p>
	      </sidebyside>
	      <sidebyside width="45%">
		<image source="preview/eigenvectors-preview.png"/>
	      </sidebyside>
	    </static>
	  </interactive>
	</figure>

	<p> Choose the matrix
	<m>A=
	\left[\begin{array}{rr}
	1\amp 2 \\
	2\amp 1 \\
	\end{array}\right]
	</m>.
	Move the vector <m>\vvec</m> so that the eigenvector condition
	holds.  What is the eigenvector <m>\vvec</m> and what is the
	associated eigenvalue?
	</p></li>

	<li><p> By algebraically computing <m>A\vvec</m>, verify that
	the eigenvector condition holds for the vector <m>\vvec</m>
	that you found.  </p></li>

	<li><p> If you multiply the eigenvector <m>\vvec</m> that you
	found by <m>2</m>, do you still have an eigenvector?  If so,
	what is the associated eigenvalue? </p></li>

	<li><p> Are you able to find another eigenvector <m>\vvec</m>
	that is not a scalar multiple of the first one that you found?
	If so, what is the eigenvector and what is the associated
	eigenvalue? </p></li>

	<li><p> Now consider the matrix
	<m>A = \left[\begin{array}{rr}
	2 \amp 1 \\
	0 \amp 2 \\
	\end{array}\right]
	</m>.
	Use the diagram to describe any eigenvectors and associated
	eigenvalues.
	</p></li>

	<li><p> Finally, consider the matrix
	<m>A = \left[\begin{array}{rr}
	0 \amp -1 \\
	1 \amp 0 \\
	\end{array}\right]
	</m>.
	Use the diagram to describe any eigenvectors and associated
	eigenvalues.  What geometric transformation does this
	matrix perform on vectors?  How does this explain the presence
	of any eigenvectors?
	</p></li>
      </ol> </p>
      </statement>

      <solution>
	<p><ol marker="a.">
	  <li><p> The vectors <m>\vvec</m> and <m>\lambda\vvec</m> lie
	  on the same line. </p></li>

	  <li><p> The vectors <m>\vvec</m> and <m>A\vvec</m> lie on
	  the same line. </p></li>

	  <li><p> There are many possibilities, but we see that
	  <m>\twovec{1}{1}</m> is an eigenvector with associated
	  eigenvalue <m>\lambda=3</m>. </p></li>

	  <li><p> If we perform the matrix multiplication, we see that
	  <m>A\twovec{1}{1} = \twovec{3}{3} =
	  3\twovec{1}{1}</m>. </p></li> 

	  <li><p> Yes, <m>\twovec{2}{2}</m> is still an eigenvector
	  with associated eigenvalue <m>\lambda=3</m>. </p></li>

	  <li><p> We see that <m>\twovec{1}{-1}</m> is an eigenvector
	  with associated eigenvalue <m>\lambda=-1</m>. </p></li>

	  <li><p> The only eigenvectors that appear are scalar
	  multiples of <m>\twovec{1}{0}</m> with associated eigenvalue
	  <m>\lambda=2</m>. </p></li>

	  <li><p> There are no eigenvectors.  The matrix
	  transformation rotates vectors by <m>90^\circ</m> so it is
	  not possible for <m>\vvec</m> and <m>A\vvec</m> to lie on
	  the same line. </p></li>
	</ol></p>
      </solution>
    </activity>

    <p> Let's consider the ideas we saw in the activity in some more
    depth.  To be an eigenvector of <m>A</m>, the vector <m>\vvec</m>
    must satisfy <m>A\vvec = \lambda\vvec</m> for some scalar
    <m>\lambda</m>.  This means that <m>\vvec</m> and <m>A\vvec</m>
    are scalar multiples of each other so they must lie on
    the same line. </p>

    <p> Consider now the matrix
    <m>A = \left[\begin{array}{rr}
    1 \amp 2 \\
    2 \amp 1 \\
    \end{array}\right]
    </m>.
    On the left of <xref ref="fig-eigen-intro" />, we see that
    <m>\vvec=\twovec{1}{0}</m> is not an eigenvector of <m>A</m> since
    the vectors <m>\vvec</m> and <m>A\vvec</m> do not lie on the same
    line.  On the right, however, we see that
    <m>\vvec=\twovec{1}{1}</m> is an eigenvector.  In fact,
    <m>A\vvec</m> is obtained from <m>\vvec</m> by stretching
    <m>\vvec</m> by a factor of <m>3</m>.  Therefore, <m>\vvec</m> is
    an eigenvector of <m>A</m> with eigenvalue <m>\lambda = 3</m>.
    </p>

    <figure xml:id="fig-eigen-intro">
      <sidebyside widths="45% 45%">
	<image source="images/eigen-intro-1-0">
          <shortdescription>
            A vector that is not an eigenvector of the matrix A and
            the result of multiplying it by A.
          </shortdescription>
          <description>
            <p>The vectors <m>\vvec=\twovec10</m> and
            <m>A\vvec=\twovec12</m> are shown.  The key point is that
            these vectors do not lie on the same line.</p>
          </description>
        </image>
	<image source="images/eigen-intro-1-1">
          <shortdescription>
            An eigenvector of the matrix and the result of multiplying
            it by the matrix.
          </shortdescription>
          <description>
            <p>The vectors <m>\vvec=\twovec11</m> and
            <m>A\vvec=\twovec33</m>.  This shows that <m>\vvec</m> is
            an eigenvector of the matrix <m>A</m> since they lie on
            the same line.</p>
          </description>
        </image>
      </sidebyside>
      <caption>
	On the left, the vector <m>\vvec</m> is not an eigenvector.
	On the right, the vector <m>\vvec</m> is an eigenvector with
	eigenvalue <m>\lambda = 3</m>.
      </caption>
    </figure>

    <p> It is not difficult to see that any multiple of
    <m>\twovec{1}{1}</m> is also an eigenvector of <m>A</m> with
    eigenvalue <m>\lambda = 3</m>.  Indeed, we will see later that all
    the eigenvectors associated to a given eigenvalue form a
    subspace of <m>\real^n</m>. </p>

    <p> In <xref ref="fig-eigen-intro-2" />, we see that
    <m>\vvec=\twovec{-1}{1}</m> is also an eigenvector with eigenvalue
    <m>\lambda =-1</m>.
    </p>

    <figure xml:id="fig-eigen-intro-2">
      <sidebyside width="45%">
	<image source="images/eigen-intro-1-m1">
          <shortdescription>
            Another eigenvector of A and the result of multiplying it
            by A.
          </shortdescription>
          <description>
            <p>The vectors <m>\vvec=\twovec{-1}1</m> and
            <m>A\vvec=\twovec1{-1}</m>.  This demonstrates that
            <m>\vvec</m> is an eigenvector of the matrix <m>A</m>
            since they lie on the same line.</p>
          </description>
        </image>
      </sidebyside>
      <caption>
	Here we see another eigenvector <m>\vvec</m> with eigenvalue
	<m>\lambda = -1</m>.
      </caption>
    </figure>

    <p> The interactive diagram we used in the activity is meant to
    convey the fact that the eigenvectors of a matrix <m>A</m> are
    special vectors.  Most of the time, the vectors <m>\vvec</m> and
    <m>A\vvec</m> appear visually unrelated.  For certain vectors,
    however, <m>\vvec</m> and <m>A\vvec</m> line up with one another.
    Something important is going on when that happens so we 
    call attention to these vectors by calling them eigenvectors.
    For these vectors, the operation of multiplying by
    <m>A</m> reduces to the much simpler operation of scalar
    multiplying by <m>\lambda</m>.  The reason eigenvectors are
    important is because it is extremely convenient to be able to
    replace matrix multiplication by scalar multiplication.
    </p>

  </subsection>

  <subsection xml:id="subsec-eigen-use">
    <title> The usefulness of eigenvalues and eigenvectors </title>

    <p> In the next section, we will introduce an algebraic technique
    for finding the eigenvalues and eigenvectors of a matrix.  Before
    doing that, however, we would like to discuss why eigenvalues and
    eigenvectors are so useful.
    </p>

    <p> Let's continue looking at the example
    <m>A = \left[\begin{array}{rr} 1 \amp 2 \\ 2 \amp 1 \\
    \end{array}\right] </m>.  We have seen that <m>\vvec_1 =
    \twovec{1}{1}</m> is an eigenvector with eigenvalue
    <m>\lambda=3</m> and <m>\vvec_2=\twovec{-1}{1}</m> is an
    eigenvector with eigenvalue <m>\lambda = -1</m>.  This means that
    <m>A\vvec_1 = 3\vvec_1</m> and <m>A\vvec_2=-\vvec_2</m>.
    By the linearity of matrix multiplication, we can
    determine what happens when we multiply a linear
    combination of <m>\vvec_1</m> and <m>\vvec_2</m> by <m>A</m>:
    <me>A(c_1\vvec_1 + c_2\vvec_2) = 3c_1\vvec_1 - c_2\vvec_2</me>.
    </p>

    <sidebyside widths="50% 50%">
      <p>
	For instance, if we consider the vector
	<m>\xvec=\vvec_1-2\vvec_2</m>, we find that
	<me>
	  \begin{aligned}
	  A\xvec\amp{}={}A(\vvec_1 - 2\vvec_2) \\
	  A\xvec\amp{}={} 3\vvec_1 + 2\vvec_2
	  \end{aligned}
	</me>
	as seen in the figure.
      </p>
      <image source="images/eigen-basis">
        <shortdescription>
          A linear combination of eigenvectors and the result of
          multiplying it by the matrix.
        </shortdescription>
        <description>
          <p>Vectors <m>\vvec_1=\twovec11</m> and
          <m>\vvec_2=\twovec{-1}1</m> and the skewed coordinate grid
          of their linear combinations.  The vector
          <m>\xvec=\vvec_1-2\vvec_2</m> and its product
          <m>A\xvec=3\vvec_1+2\vvec_2</m> show how the product can be
          easily expressed as a linear combination of
          eigenvectors.</p>
        </description>
      </image>
    </sidebyside>

    <p> In other words, multiplying by <m>A</m> has the effect of
    stretching a vector <m>\xvec</m> in the
    <m>\vvec_1</m> direction by a factor of <m>3</m> and flipping 
    <m>\xvec</m> in <m>\vvec_2</m> direction.
    </p>

    <p> We can draw an analogy with the more familiar example of the
    diagonal matrix 
    <m>D=\left[\begin{array}{rr}
    3 \amp 0 \\
    0 \amp -1 \\
    \end{array}\right]
    </m>.
    As we have seen, the matrix transformation defined by <m>D</m>
    combines a horizontal stretching by a factor of 3 with a
    reflection across the horizontal axis, as is illustrated
    in <xref ref="fig-eigen-intro-diagonal" />.
    </p>

    <figure xml:id="fig-eigen-intro-diagonal">
      <sidebyside width="80%">
	<image source="images/eigen-intro-diagonal">
          <shortdescription>
            The unit square and the effect that multiplication by the
            diagonal matrix has on it.
          </shortdescription>
          <description>
            <p>On the left is shown the unit square, the
            <m>1\times1</m> square with vertices at the origin and
            <m>(1,1)</m>.  On the right is the rectangle with vertices
            at the origin, <m>(3,0)</m>, <m>(3,-1)</m>, and
            <m>(0,-1)</m>, which shows how the unit square is
            transformed by multiplication by the diagonal matrix
            <m>D</m>.</p>
          </description>
        </image>
      </sidebyside>
      <caption> The diagonal matrix <m>D</m> stretches vectors
      horizontally by a factor of <m>3</m> and flips vectors
      vertically. 
      </caption>
    </figure>

    <p> The matrix
    <m>A=\left[\begin{array}{rr}
    1 \amp 2 \\
    2 \amp 1 \\
    \end{array}\right]
    </m>
    has a similar effect when viewed in the basis defined by the
    eigenvectors <m>\vvec_1</m> and <m>\vvec_2</m>, as seen in <xref
    ref="fig-eigen-intro-A" />.
    </p>
    
    <figure xml:id="fig-eigen-intro-A">
      <sidebyside width="80%">
	<image source="images/eigen-intro-A">
          <shortdescription>
            Multiplication by A transforms a rotated square into a
            rotated rectangle.
          </shortdescription>
          <description>
            <p>On the left is shown the eigenvectors <m>\vvec_1</m>
            and <m>\vvec_2</m> and the skewed coordinate grid of their
            linear combinations.  The square whose vertices are the
            origin, <m>\vvec_1</m>, <m>\vvec_1+\vvec_2</m>, and
            <m>\vvec_2</m> is also shaded.</p>
            <p>The effect of multiplying these features by <m>A</m> is
            shown on the right.  The vectors <m>3\vvec_1</m> and
            <m>-\vvec_2</m> are shown along with the rectangle whose
            vertices are at the origin, <m>3\vvec_1</m>,
            <m>3\vvec_1-\vvec_2</m>, and <m>-\vvec_2</m>.  This
            rectangle shows how the square on the left is transformed
            under multiplication by <m>A</m>.</p>
            <p>This diagram is similar to <xref
            ref="fig-eigen-intro-diagonal"/> except that the square on
            the left and the rectangle on the right are rotated by
            <m>45</m> degrees.</p>
          </description>
        </image>
      </sidebyside>
      <caption> The matrix <m>A</m> has the same geometric effect as
      the diagonal matrix <m>D</m> when expressed in the
      coordinate system defined by the basis of eigenvectors.  
      </caption>
    </figure>

    <p> In a sense that will be made precise later, having a set of
    eigenvectors of <m>A</m> that forms a basis of <m>\real^2</m>
    enables us to think of <m>A</m> as being equivalent to a diagonal
    matrix <m>D</m>.  Of course, as the other examples in the previous
    activity show, it may not always be possible to form a basis from the
    eigenvectors of a matrix.  For example, the only eigenvectors of
    the matrix <m>\left[\begin{array}{rr} 2 \amp 1 \\ 0 \amp 2
    \end{array}\right]</m>, which represents a shear, have the form
    <m>\twovec{x}{0}</m>.  In this example, we are not able to create
    a basis for <m>\real^2</m> consisting of eigenvectors of the
    matrix.  This is also true for the matrix
    <m>
      \left[\begin{array}{rr}
      0 \amp -1 \\
      1 \amp 0 \\
      \end{array}\right]
      </m>,
      which represents a <m>90^\circ</m> rotation.
    </p>

    <activity xml:id="activity-eigen-intro">
      <statement>
      <p> Let's consider an example that illustrates how we can put
      these ideas to use. </p>

      <p> Suppose that we work for a car rental company that has two
      locations, <m>P</m> and <m>Q</m>.  When a customer rents a car
      at one location, they have the option to return it to either
      location at the end of the day.  After doing some market
      research, we determine:
      <ul>
	<li><p> 80% of the cars rented at location <m>P</m> are
	returned to <m>P</m> and 20% are returned to
	<m>Q</m>. </p></li> 

	<li><p> 40% of the cars rented at location <m>Q</m> are
	returned to <m>Q</m> and 60% are returned to
	<m>P</m>. </p></li>
      </ul>

      <ol marker="a.">
	<li><p> Suppose that there are 1000 cars at location <m>P</m>
	and no cars at location <m>Q</m> on Monday morning.  How many
	cars are there are locations <m>P</m> and <m>Q</m> at the end
	of the day on Monday?  </p></li>

	<li><p> How many are at locations <m>P</m> and <m>Q</m> at end
	of the day on Tuesday? </p></li>

	<li><p> If we let <m>P_k</m> and <m>Q_k</m> be the number of
	cars at locations <m>P</m> and <m>Q</m>, respectively, at the
	end of day <m>k</m>, we then have
	<me>
	  \begin{aligned}
	  P_{k+1}\amp {}={} 0.8P_k + 0.6Q_k \\
	  Q_{k+1}\amp {}={} 0.2P_k + 0.4Q_k\text{.} \\
	  \end{aligned}
	</me>
	We can write the vector <m>\xvec_k = \twovec{P_k}{Q_k}</m> to
	reflect the number of cars at the two locations at the end of
	day <m>k</m>, which says that
	<me>
	  \xvec_{k+1} =
	  \left[\begin{array}{rr}
	  0.8 \amp 0.6 \\
	  0.2 \amp 0.4 \\
	  \end{array}\right]
	  \xvec_k
	</me>
	or <m>\xvec_{k+1} = A\xvec_k</m>
	where <m>A=\left[\begin{array}{rr}0.8 \amp 0.6 \\ 0.2 \amp 0.4
	\end{array}\right]</m>.
      </p>
      <p> Suppose that
      <me>
	\vvec_1 = \twovec{3}{1},
	\qquad
	\vvec_2 = \twovec{-1}{1}
      </me>.
      Compute <m>A\vvec_1</m> and <m>A\vvec_2</m> to demonstrate that
      <m>\vvec_1</m> and <m>\vvec_2</m> are eigenvectors of <m>A</m>.
      What are the associated eigenvalues <m>\lambda_1</m> and
      <m>\lambda_2</m>?  </p></li>

      <li><p> We said that 1000 cars are initially at location
      <m>P</m> and none at location <m>Q</m>.  This means that the
      initial vector describing the number of cars is <m>\xvec_0 =
      \ctwovec{1000}{0}</m>.  Write <m>\xvec_0</m> as a linear
      combination of <m>\vvec_1</m> and <m>\vvec_2</m>. </p></li>

      <li><p> Remember that <m>\vvec_1</m> and <m>\vvec_2</m>
      are eigenvectors of <m>A</m>.  Use the linearity of matrix
      multiplication to write the vector <m>\xvec_1 =
      A\xvec_0</m>, describing the number of cars at the two locations
      at the end of the first day, as a linear combination of
      <m>\vvec_1</m> and <m>\vvec_2</m>.  </p></li>

      <li><p> Write the vector <m>\xvec_2 = A\xvec_1</m> as a linear
      combination of <m>\vvec_1</m> and <m>\vvec_2</m>.  Then write
      the next few vectors as linear combinations of <m>\vvec_1</m>
      and <m>\vvec_2</m>:
      <ol marker="1.">
	<li><p> <m>\xvec_3 = A\xvec_2</m>. </p></li>
	<li><p> <m>\xvec_4 = A\xvec_3</m>. </p></li>
	<li><p> <m>\xvec_5 = A\xvec_4</m>. </p></li>
	<li><p> <m>\xvec_6 = A\xvec_5</m>. </p></li>
      </ol>
      </p></li>

      <li><p> What will happen to the number of cars at the two
      locations after a very long time?  Explain how writing
      <m>\xvec_0</m> as a linear combination of eigenvectors helps you
      determine the long-term behavior. </p></li>
      </ol></p>
      </statement>

      <solution>
	<p> The solution to this activity is given in the text
	below. </p> 
      </solution>
    </activity>

    <p> This activity is important and motivates much of our work with
    eigenvalues and eigenvectors so it's worth reviewing
    to make sure we have a clear understanding of the concepts.
    </p>

    <p> First, we compute
    <me>
      \begin{aligned}
      A\vvec_1 =
      \left[\begin{array}{rr}
      0.8 \amp 0.6 \\
      0.2 \amp 0.4 \\
      \end{array}\right]
      \twovec{3}{1}
      \amp {}={}
      \twovec{3}{1}
      = 1\vvec_1
      \\
      \\
      A\vvec_2 =
      \left[\begin{array}{rr}
      0.8 \amp 0.6 \\
      0.2 \amp 0.4 \\
      \end{array}\right]
      \twovec{-1}{1}
      \amp {}={}
      \twovec{-0.2}{0.2}
      = 0.2\vvec_2\text{.} \\
      \end{aligned}
    </me>
    This shows that <m>\vvec_1</m> is an eigenvector of <m>A</m> with
    eigenvalue <m>\lambda_1 = 1</m> and <m>\vvec_2</m> is an
    eigenvector of <m>A</m> with eigenvalue <m>\lambda_2=0.2</m>.
    </p>

    <p> By the linearity of matrix matrix multiplication, we have
    <me>
      A(c_1\vvec_1 + c_2\vvec_2) = c_1\vvec_1 + 0.2c_2\vvec_2
    </me>.
    Therefore, we will write the vector describing the initial
    distribution of cars 
    <m>\xvec_0=\ctwovec{1000}{0}</m> as a linear combination of
    <m>\vvec_1</m> and <m>\vvec_2</m>;  that is, <m>\xvec_0 =
    c_1\vvec_2 + c_2 \vvec_2</m>.  To do, we form the augmented matrix
    and row reduce:
    <me>
      \left[\begin{array}{rr|r}
      \vvec_1 \amp \vvec_2 \amp \xvec_0
      \end{array}\right]
      =
      \left[\begin{array}{rr|r}
      3 \amp -1 \amp 1000 \\
      1 \amp 1 \amp 0 \\
      \end{array}\right]
      \sim
      \left[\begin{array}{rr|r}
      1 \amp 0 \amp 250 \\
      0 \amp 1 \amp -250 \\
      \end{array}\right]
    </me>.
    Therefore, <m>\xvec_0 = 250\vvec_1 -250\vvec_2</m>.
    </p>

    <p> To determine the distribution of cars on subsequent days, we
    will repeatedly multiply by <m>A</m>.  We find that
    <me>
      \begin{aligned}
      \xvec_1 = A\xvec_0 \amp {}={}
      A(250\vvec_1 - 250\vvec_2) = 250\vvec_1 - (0.2)250\vvec_2 \\
      \xvec_2 = A\xvec_1 \amp {}={}
      A(250\vvec_1 - (0.2)250\vvec_2) = 250\vvec_1 - (0.2)^2250\vvec_2 \\
      \xvec_3 = A\xvec_2 \amp {}={}
      A(250\vvec_1 - (0.2)^2250\vvec_2) = 250\vvec_1 - (0.2)^3250\vvec_2 \\
      \xvec_4 = A\xvec_3 \amp {}={}
      A(250\vvec_1 - (0.2)^3250\vvec_2) = 250\vvec_1 - (0.2)^4250\vvec_2 \\
      \xvec_5 = A\xvec_4 \amp {}={}
      A(250\vvec_1 - (0.2)^4250\vvec_2) = 250\vvec_1 - (0.2)^5250\vvec_2 \\
      \end{aligned}
    </me>.
    </p>

    <p> In particular, this shows us that
    <me>
      \xvec_5 = 250\vvec_1 - (0.2)^5250\vvec_2 =
      \twovec{250\cdot 3 - (0.2)^5250\cdot(-1)}
      {250\cdot 1 - (0.2)^5250\cdot 1}
      = \twovec{750.09}{249.92}
    </me>.
    Taking notice of the pattern, we may write
    <me>
      \xvec_k = 250\vvec_1 - (0.2)^k250\vvec_2
    </me>.
    Multiplying a number by <m>0.2</m> is the same as taking 20% of
    that number.  As each day goes by, the second term is multiplied
    by <m>0.2</m> so the coefficient of <m>\vvec_2</m> in the
    expression for <m>\xvec_k</m> will eventually become extremely
    small.  We therefore see that the distribution of cars will 
    stabilize at <m>\xvec=250\vvec_1=\twovec{750}{250}</m>.
    </p>

    <p>
      Notice how our understanding of the eigenvectors of the matrix
      allows us to replace matrix multiplication with the simpler
      operation of scalar multiplication.  As a result, we can look
      far into the future without having to repeatedly perform matrix
      multiplication.
    </p>

    <p>
      Furthermore, notice how this example relies on the fact that we
      can express the initial vector <m>\xvec_0</m> as a linear
      combination of eigenvectors.  For this reason, we would like,
      when given an <m>n\times n</m> matrix, to be able to create a
      basis of <m>\real^n</m> that consists of its eigenvectors.  We
      will frequently return to this question in later sections.
    </p>

    <question xml:id ="question-eigen-basis">
      <statement>
	<p> If <m>A</m> is an <m>n\times n</m> matrix, can we form a
	basis of <m>\real^n</m> consisting of eigenvectors of
	<m>A</m>? </p>
      </statement>
    </question>

  </subsection>

  <subsection>
    <title> Summary </title>

    <p> We defined an eigenvector of a square matrix <m>A</m> to be a
    nonzero vector <m>\vvec</m> such that <m>A\vvec = \lambda\vvec</m>
    for some scalar <m>\lambda</m>, which is called the eigenvalue
    associated to <m>\vvec</m>.
    <ul>
      <li><p> If <m>\vvec</m> is an eigenvector, then matrix
      multiplication by <m>A</m> reduces to the simpler operation of
      scalar multiplication by <m>\lambda</m>. </p></li>

      <li><p> Scalar multiples of an eigenvector are also
      eigenvectors.  In fact, we will see that the eigenvectors
      associated to an eigenvalue <m>\lambda</m> form a
      subspace. </p></li>

      <li><p> If we can form a basis for <m>\real^n</m> consisting of
      eigenvectors of <m>A</m>, then <m>A</m> is, in some sense,
      equivalent to a diagonal matrix. </p></li>

      <li><p> Rewriting a vector <m>\xvec</m> as a linear combination
      of eigenvectors of <m>A</m> simplifies the process of repeatedly
      multiplying <m>\xvec</m> by <m>A</m>. </p></li>
    </ul>
    </p>

    <exercise component="proteus"
              label="ula-proteus-4-1-eigen-def">
      <title>
        Using the definition of eigenvectors and
        eigenvalues
      </title>
      <introduction>
        <p>
          Respond to this set of questions by referring to the
          <xref ref="definition-eigenvectors" text="custom">
            definition of eigenvectors
          </xref>
          and the
          <xref ref="prop-matrix-mult-prop" text="custom">
            linearity of matrix multiplication.
          </xref>
        </p>
      </introduction>

      <task label="ula-proteus-intro_eigen_significance">
        <statement>
          <p>What does it mean for a vector <m>\vvec</m> to be an
          eigenvector of a matrix <m>A</m>?</p>
        </statement>
        <response/>
      </task>

      <task label="ula-proteus-intro_eigen_check_w">
        <statement>
          <p>Is <m>\wvec=\twovec{2}{-1}</m> an eigenvector of the matrix
          <m>M=\begin{bmatrix} 7 \amp 2 \\ 1 \amp 8 \end{bmatrix}</m>?
          If so, what is the associated eigenvalue?  Explain your
          response.
          </p>
        </statement>
        <response/>
      </task>

      <task label="ula-proteus-intro_eigen_show_A2">
        <statement>
          <p>Suppose that <m>\vvec</m> is an eigenvector of a
          matrix <m>A</m> with eigenvalue 3.  Use algebra to show that
          <m>A^2\vvec = 9\vvec</m>.
          </p>
        </statement>
        <response/>
      </task>

      <task label="ula-proteus-intro_eigen_ev_for_A2">
        <statement>
          <p>If <m>\vvec</m> is an eigenvector of a matrix <m>A</m>
          with eigenvalue 3, is <m>\vvec</m> necessarily an
          eigenvector of <m>A^2</m>?  Explain your reasoning.
          </p>
        </statement>
        <response/>
      </task>

      <task label="ula-proteus-intro_eigen_ev_for_A10">
        <statement>
          <p>If <m>\vvec</m> is an eigenvector of a matrix <m>A</m>
          with eigenvalue 3, is <m>\vvec</m> necessarily an
          eigenvector of <m>A^{10}</m>?  Explain your reasoning.
          </p>
        </statement>
        <response/>
      </task>

    </exercise>

    <exercise component="proteus"
              label="ula-proteus-4-1-identifying-eigenvectors">
      <title>Identifying eigenvectors and eigenvalues of a
      matrix</title>

      <statement>
        <p>Suppose that
        <m>A=\begin{bmatrix}
        -1 \amp 1 \amp -4 \\
        -1 \amp 1 \amp 2 \\
        -3 \amp 3 \amp 3 \\
        \end{bmatrix}
        </m>.
        Determine whether each of the vectors on the left is an
        eigenvector of <m>A</m>.
        </p>
      </statement>

      <cardsort>
        <match>
          <premise>
            <m>\threevec1{-1}{-2}</m>
          </premise>
          <premise>
            <m>\threevec{-1}{1}{2}</m>
          </premise>
          <response>
            <p>Eigenvector of <m>A</m> with eigenvalue
            <m>\lambda=6</m>.
            </p>
          </response>
        </match>

        <match>
          <premise>
            <m>\threevec110</m>
          </premise>
          <response>
            <p>Eigenvector of <m>A</m> with eigenvalue
            <m>\lambda=0</m>.
            </p>
          </response>
        </match>

        <match>
          <premise>
            <m>\threevec201</m>
          </premise>
          <response>
            <p>Eigenvector of <m>A</m> with eigenvalue
            <m>\lambda=-3</m>.
            </p>
          </response>
        </match>

        <match>
          <premise>
            <m>\fourvec1{-1}20</m>
          </premise>
          <premise>
            <m>\threevec11{-1}</m>
          </premise>
          <response>
            Not an eigenvector of <m>A</m>.
          </response>
        </match>
      </cardsort>
    </exercise>

    <exercise component="proteus"
              label="ula-proteus-4-1-linearity-v1">
      <title>Applying linearity to products of eigenvectors</title>
      <statement>
        <p>Suppose <m>\vvec_1</m> and <m>\vvec_2</m> are
        eigenvectors for a matrix <m>A</m> such that
        <m>A\vvec_1=3\vvec_1</m> and  <m>A\vvec_2=(-1)\vvec_2</m>. Use
        linearity of matrix multiplication to match the products on the
        left with an equivalent vector on the right.</p>
      </statement>
      <cardsort>
        <match>
          <premise ><m>A(2\vvec_1)</m></premise>
          <response><m>6\vvec_1</m></response>
        </match>
        <match>
          <premise ><m>A^2\vvec_1</m></premise>
          <response><m>9\vvec_1</m></response>
        </match>
        <match>
          <premise ><m>A(\vvec_1+\vvec_2)</m></premise>
          <response><m>3\vvec_1-\vvec_2</m></response>
        </match>
        <match>
          <premise ><m>A^7\vvec_2</m></premise>
          <response><m>-\vvec_2</m></response>
        </match>
        <match>
          <premise ><m>A(2\vvec_1-2\vvec_2)</m></premise>
          <response><m>6\vvec_1+2\vvec_2</m></response>
        </match>
        <match>
          <response ><m>2\vvec_1</m></response>
        </match>
        <match>
          <response ><m>\zerovec</m></response>
        </match>
      </cardsort>
    </exercise>

    <exercise component="proteus"
              label="ula-proteus-4-1-using-eigenvectors-to-compute-matrix-power-times-vector">
      <title>Using eigenvectors in computations involving matrix powers</title>
      <introduction>
        <p>
          Suppose that a <m>2\times 2</m> matrix <m>A</m> has an
          eigenvector <m>\vvec_1=\twovec{1}{-1}</m>
          with eigenvalue <m>-1</m>
          and an eigenvector <m>\vvec_2=\twovec{2}{1}</m> with
          eigenvalue <m>2</m>. Let <m>\xvec= \twovec{7}{-1}</m>.
        </p>
      </introduction>
      <task label="ula-proteus-4-1-using-eigenvectors-to-compute-matrix-power-times-vector-taskA">
        <statement>
          <p> Express <m>\xvec</m>  as a linear combination of
          <m>\vvec_1</m> and <m>\vvec_2</m>.</p>
        </statement>
        <response/>
      </task>
      <task label="ula-proteus-4-1-using-eigenvectors-to-compute-matrix-power-times-vector-taskB">
        <statement>
          <p> Find <m>A^5\xvec</m>. Explain your thinking.</p>
        </statement>
        <response/>
      </task>
    </exercise>

  </subsection>

  <xi:include href="exercises/exercises4-1.xml" /> 

</section>

