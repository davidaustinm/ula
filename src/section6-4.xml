<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-gram-schmidt"
	 xmlns:xi="http://www.w3.org/2001/XInclude">
  <title> Finding orthogonal bases  </title>

  <introduction>
    <p>
      The last section demonstrated the value of working with
      orthogonal, and especially orthonormal, sets.  If we have an
      orthogonal basis <m>\wvec_1,\wvec_2,\ldots,\wvec_n</m> for a
      subspace <m>W</m>, the <xref
      ref="prop-proj-formula">Projection Formula</xref>
      tells us that the orthogonal projection
      of a vector <m>\bvec</m> onto <m>W</m> is
      <me>
	\bhat =
	\frac{\bvec\cdot\wvec_1}{\wvec_1\cdot\wvec_1}~\wvec_1 + 
	\frac{\bvec\cdot\wvec_2}{\wvec_2\cdot\wvec_2}~\wvec_2 +
	\cdots + 
	\frac{\bvec\cdot\wvec_n}{\wvec_n\cdot\wvec_n}~\wvec_n\text{.}
      </me>
      An orthonormal basis <m>\uvec_1,\uvec_2,\ldots,\uvec_n</m>
      is even more convenient:  after forming the matrix
      <m>Q=\begin{bmatrix} \uvec_1 \amp \uvec_2 \amp \ldots \amp
      \uvec_n
      \end{bmatrix}</m>, we have <m>\bhat = QQ^T\bvec</m>.
    </p>
      
    <p>
      In the examples we've seen so far, however, orthogonal bases
      were given to us.  What we need now is a way to form orthogonal
      bases.  In this section, we'll explore an algorithm that begins
      with a basis for a subspace and creates an
      orthogonal basis. Once we have an orthogonal basis, we can scale
      each of the vectors appropriately to produce an orthonormal
      basis.
    </p>

    <exploration label="ula-preview-6-4">
      <introduction>
        <p>
	  Suppose we have a basis for <m>\real^2</m> consisting of
	  the vectors
	  <me>
	    \vvec_1=\twovec11,\hspace{24pt}
	    \vvec_2=\twovec02
	  </me>
	  as shown in <xref ref="fig-gs-intro" />.  Notice that this basis
	  is not orthogonal.
        </p>
        <figure xml:id="fig-gs-intro">
	  <sidebyside width="50%">
	    <image source="images/gram-schmidt-intro">
              <shortdescription>
                Two vectors in the two dimensional coordinate plane
                that are not orthogonal to one another.
              </shortdescription>
              <description>
                <p>Two vectors <m>\vvec_1=\twovec11</m> and
                <m>\vvec_2=\twovec02</m> against a <m>1\times1</m>
                standard coordinate grid and set of axes.</p>
              </description>
            </image>
	  </sidebyside>
	  <caption>
	    A basis for <m>\real^2</m>.
	  </caption>
        </figure>
      </introduction>

      <task label="ula-preview-6-4-a">
        <statement>
	  <p>
	    Find the vector <m>\vhat_2</m> that is the orthogonal
	    projection of
	    <m>\vvec_2</m> onto the line defined by <m>\vvec_1</m>.
	  </p>
        </statement>
        <response component="rs-preview"/>
        <solution>
	  <p>
	    <m>\vhat_2 = \vvec_1</m>.
	  </p>
        </solution>
      </task>

      <task label="ula-preview-6-4-b">
        <statement>
	  <p>
	    Explain why <m>\vvec_2 - \vhat_2</m> is orthogonal to
	    <m>\vvec_1</m>.
	  </p>
	</statement>
        <response component="rs-preview"/>
        <solution>
	  <p>
	    The orthogonal projection <m>\vhat_2</m> is defined so
	    that <m>\vvec_2-\vhat_2</m> is orthogonal to
	    <m>\vvec_1</m>.
	  </p>
        </solution>
      </task>

      <task label="ula-preview-6-4-c"
            attachment="yes">
        <statement>
	  <p>
	    Define the new vectors <m>\wvec_1=\vvec_1</m> and
	    <m>\wvec_2=\vvec_2-\vhat_2</m> and sketch them in <xref
	    ref="fig-gs-empty" />.  Explain why <m>\wvec_1</m> and
	    <m>\wvec_2</m> define an orthogonal basis for <m>\real^2</m>.
	  </p>
          <p component="rs-preview">You can upload a scan of your sketch below.</p>
	  
	  <figure xml:id="fig-gs-empty">
	    <sidebyside width="50%">
	      <image source="images/empty-3">
                <shortdescription>
                  A two dimensional coordinate grid and set of axes.
                </shortdescription>
                <description>
                  <p>A <m>1\times1</m> coordinate grid and set of
                  axes.  The horizontal and vertical ranges run from
                  <m>-3</m> to <m>3</m>.</p>
                </description>
              </image>
	    </sidebyside>
	    <caption>
	      Sketch the new basis <m>\wvec_1</m> and <m>\wvec_2</m>.
	    </caption>
	  </figure>
        </statement>
        <response component="rs-preview"/>
        <solution>
	  <p>
	    <m>\wvec_1 = \twovec11</m> and
	    <m>\wvec_2=\twovec{-1}1</m> are othogonal, which can
	    be checked with the dot product.
	  </p>
        </solution>
      </task>

      <task label="ula-preview-6-4-d">
        <statement>
	  <p>
	    Write the vector <m>\bvec=\twovec8{-10}</m> as a linear
	    combination of <m>\wvec_1</m> and <m>\wvec_2</m>.
	  </p>
        </statement>
        <response component="rs-preview"/>
        <solution>
	  <p>
	    The projection formula gives <m>\bvec = -\wvec_1
	    -9\wvec_2</m>.
	  </p>
        </solution>
      </task>

      <task label="ula-preview-6-4-e">
        <statement>
	  <p>
	    Scale the vectors <m>\wvec_1</m> and <m>\wvec_2</m> to
	    produce an orthonormal basis <m>\uvec_1</m> and
	    <m>\uvec_2</m> for <m>\real^2</m>.
	  </p>
        </statement>
        <response component="rs-preview"/>
        <solution>
	  <p>
	    <m>\uvec_1=\frac1{\sqrt{2}}\twovec11</m> and
	    <m>\uvec_2=\frac1{\sqrt{2}}\twovec{-1}1</m>.
	  </p>
        </solution>
      </task>

      <task component="rs-preview">
        <query label="ula-preview-6-4-poll" visibility="instructor">
          <statement>
            <p>I feel confident with the material in this activity.</p>
          </statement>
          <choices>
            <choice><p>Strongly Agree</p></choice>
            <choice><p>Agree</p></choice>
            <choice><p>Neutral</p></choice>
            <choice><p>Disagree</p></choice>
            <choice><p>Strongly Disagree</p></choice>
          </choices>
        </query>
      </task>

      <task component="rs-preview"
            label="ula-preview-6-4-what-else">
        <statement>
          <p>What would you need to know to feel
          more confident about this material?</p>
        </statement>
        <response/>
      </task>
    </exploration>

  </introduction>

  <subsection>
    <title> Gram-Schmidt orthogonalization </title>

    <p>
      <idx>Gram-Schmidt</idx> The preview activity illustrates the
      main idea behind an algorithm, known as <em>Gram-Schmidt
      orthogonalization</em>, that begins with a basis for some subspace
      of <m>\real^m</m> and produces an orthogonal or orthonormal basis.
      The algorithm relies on our construction of the orthogonal
      projection.  Remember that we formed the orthogonal projection
      <m>\bhat</m> of <m>\bvec</m> onto a subspace <m>W</m> by requiring
      that <m>\bvec-\bhat</m> is orthogonal to <m>W</m> as shown in
      <xref ref="fig-proj-orthog" />.
    </p>
    
    <figure xml:id="fig-proj-orthog">
      <sidebyside width="50%">
	<image source="images/3d-orthog-proj-2">
          <shortdescription>
            Orthogonally projecting a three dimensional vector onto a
            plane.
          </shortdescription>
          <description>
            <p>Two orthogonal vectors <m>\wvec_1</m> and
            <m>\wvec_2</m> and the plane <m>W</m> they define in three
            dimensions.  A vector <m>\bvec</m> and its orthogonal
            projection <m>\bhat</m> onto <m>W</m> is shown along with
            the vector <m>\bvec-\bhat</m>, which is orthogonal to
            <m>W</m>.</p>
          </description>
        </image>
      </sidebyside>
      <caption>
	If <m>\bhat</m> is the orthogonal projection of <m>\bvec</m>
	onto <m>W</m>, then <m>\bvec-\bhat</m> is orthogonal to
	<m>W</m>. 
      </caption>
    </figure>

    <p>
      This observation guides our construction of an orthogonal
      basis for it allows us to create a vector that is orthogonal to
      a given subspace.  Let's see how the Gram-Schmidt algorithm
      works.  
    </p>

    <activity xml:id="activity-gram-schmidt">
      <statement>
	<p>
	  Suppose that <m>W</m> is a three-dimensional subspace of
	  <m>\real^4</m> with basis:
	  <me>
	    \vvec_1 = \fourvec1111,\hspace{24pt}
	    \vvec_2 = \fourvec1322,\hspace{24pt}
	    \vvec_3 = \fourvec1{-3}{-3}{-3}\text{.}
	  </me>
	  We can see that this basis is not orthogonal by noting that
	  <m>\vvec_1\cdot\vvec_2 = 8</m>.  Our goal is to create an
	  orthogonal basis <m>\wvec_1</m>, <m>\wvec_2</m>, and
	  <m>\wvec_3</m> for <m>W</m>.
	</p>
	<p>
	  To begin, we declare that <m>\wvec_1=\vvec_1</m>, and we
	  call <m>W_1</m> the line defined by <m>\wvec_1</m>.
	</p>
	<p>
	  <sage>
	    <input>
	    </input>
	  </sage>
	  <ol marker="a.">
	    <li>
	      <p>
		Find the vector <m>\vhat_2</m> that is the orthogonal
		projection of <m>\vvec_2</m> onto <m>W_1</m>, the line
		defined by <m>\wvec_1</m>.
	      </p>
	    </li>

	    <li>
	      <p>
		Form the vector <m>\wvec_2 = \vvec_2-\vhat_2</m> and
		verify that it is orthogonal to <m>\wvec_1</m>.
	      </p>
	    </li>
	    
	    <li>
	      <p>
		Explain why <m>\laspan{\wvec_1,\wvec_2} =
		\laspan{\vvec_1,\vvec_2}</m> by showing that any linear
		combination of <m>\vvec_1</m> and <m>\vvec_2</m> can be
		written as a linear combination of <m>\wvec_1</m> and
		<m>\wvec_2</m> and vice versa.
	      </p>
	    </li>

	    <li>
	      <p>
		The vectors <m>\wvec_1</m> and <m>\wvec_2</m> are an
		orthogonal basis for a two-dimensional subspace <m>W_2</m> of
		<m>\real^4</m>.  Find the vector <m>\vhat_3</m> that is the
		orthogonal projection of <m>\vvec_3</m> onto <m>W_2</m>.
	      </p>
	    </li>

	    <li>
	      <p>
		Verify that <m>\wvec_3 = \vvec_3-\vhat_3</m> is
		orthogonal to both <m>\wvec_1</m> and
		<m>\wvec_2</m>.
	      </p>
	    </li>

	    <li>
	      <p>
		Explain why <m>\wvec_1</m>, <m>\wvec_2</m>, and
		<m>\wvec_3</m> form an orthogonal basis for <m>W</m>.
	      </p>
	    </li>

	    <li>
	      <p>
		Now find an orthonormal basis for <m>W</m>.
	      </p>
	    </li>
	  </ol>
	</p>
      </statement>

      <solution>
	<p>
	  <ol marker="a.">
	    <li>
	      <p>
		<m>\widehat{\vvec}_2 = \frac{\vvec_2\cdot\wvec_1}
		{\wvec_1\cdot\wvec_1}\wvec_1=\fourvec2222</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\wvec_2 = \fourvec{-1}100</m>
	      </p>
	    </li>
	    <li>
	      <p>
		We have <m>\vvec_1 = \wvec_1</m> and <m>\vvec_2 =
		\wvec_2 + 2\wvec_1</m>.  Therefore, a linear
		combination of <m>\vvec_1</m> and <m>\vvec_1</m> can
		be rewritten as
		<me>
		  c_1\vvec_1+c_2\vvec_2 =
		  c_1\wvec_1+c_2(\wvec_2+2\wvec_1) =
		  (c_1+2c_2)\wvec_1 + c_2\wvec_2\text{.}
		</me>
		In the same way, <m>\wvec_1=\vvec_1</m> and <m>\wvec_2
		= \vvec_2-2\vvec_1</m> so any linear combination of
		<m>\wvec_1</m> and <m>\wvec_2</m> can be rewritten as
		a linear combination of <m>\vvec_1</m> and
		<m>\vvec_1</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		By the Projection Formula, <m>\widehat{\vvec}_3 =
		\fourvec0{-4}{-2}{-2}</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\wvec_3 = \fourvec11{-1}{-1}</m>
	      </p>
	    </li>
	    <li>
	      <p>
		We can check that <m>\wvec_1</m>, <m>\wvec_2</m>, and
		<m>\wvec_3</m> form an orthogonal set.  Since
		<m>\vvec_i</m> can be written in terms of
		<m>\wvec_j</m> and vice-versa, these new vectors form
		a basis for <m>W</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<me>
		  \uvec_1=\fourvec{1/2}{1/2}{1/2}{1/2},\hspace{24pt}
		  \uvec_2=\fourvec{-1/\sqrt{2}}{1/\sqrt{2}}00,\hspace{24pt}
		  \uvec_3=\fourvec{1/2}{1/2}{-1/2}{-1/2}
		</me>
	      </p>
	    </li>
	  </ol>
	</p>
      </solution>
		
      <answer>
	<p>
	  <ol marker="a.">
	    <li>
	      <p>
		<m>\widehat{\vvec}_2 = \fourvec2222</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\wvec_2 = \fourvec{-1}100</m>
	      </p>
	    </li>
	    <li>
	      <p>
		We have <m>\vvec_1 = \wvec_1</m> and <m>\vvec_2 =
		\wvec_2 + 2\wvec_1</m> so a linear
		combination of <m>\vvec_1</m> and <m>\vvec_1</m> can
		be rewritten as a linear combination of <m>\wvec_1</m>
		and <m>\wvec_2</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\widehat{\vvec}_3 =
		\fourvec0{-4}{-2}{-2}</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\wvec_3 = \fourvec11{-1}{-1}</m>
	      </p>
	    </li>
	    <li>
	      <p>
		Since
		<m>\vvec_i</m> can be written in terms of
		<m>\wvec_j</m> and vice-versa, these new vectors form
		a basis for <m>W</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<me>
		  \uvec_1=\fourvec{1/2}{1/2}{1/2}{1/2},\hspace{24pt}
		  \uvec_2=\fourvec{-1/\sqrt{2}}{1/\sqrt{2}}00,\hspace{24pt}
		  \uvec_3=\fourvec{1/2}{1/2}{-1/2}{-1/2}
		</me>
	      </p>
	    </li>
	  </ol>
	</p>
      </answer>
		
    </activity>

    <p>
      As this activity illustrates, Gram-Schmidt orthogonalization
      begins with a basis <m>\vvec_1\vvec_2,\ldots,\vvec_n</m> for a
      subspace <m>W</m> of <m>\real^m</m> and creates an orthogonal
      basis for <m>W</m>.  Let's work through a second example.
    </p>

    <example xml:id="example-gram-schmidt">
      <statement>
	<p>
	  Let's start with the basis 
	  <me>
	    \vvec_1=\threevec{2}{-1}2,\hspace{24pt}
	    \vvec_2=\threevec{-3}{3}0,\hspace{24pt}
	    \vvec_3=\threevec{-2}71\text{,}
	  </me>
	  which is a basis for <m>\real^3</m>.
	</p>

	<p>
	  To get started, we'll simply set
	  <m>\wvec_1=\vvec_1=\threevec{2}{-1}2</m>.
	  We construct <m>\wvec_2</m> from <m>\vvec_2</m> by
	  subtracting its orthogonal projection onto <m>W_1</m>, the
	  line defined 
	  by <m>\wvec_1</m>.  This gives
	  <me>
	    \wvec_2 = \vvec_2 -
	    \frac{\vvec_2\cdot\wvec_1}{\wvec_1\cdot\wvec_1}\wvec_1 =
	    \vvec_2 + \wvec_1 = \threevec{-1}22\text{.}
	  </me>
	</p>

	<p>
	  Notice that we found <m>\vvec_2 = -\wvec_1 + \wvec_2</m>.
	  Therefore, we can rewrite any linear combination of
	  <m>\vvec_1</m> and <m>\vvec_2</m> as
	  <me>
	    c_1\vvec_1 + c_2\vvec_2 = c_1\wvec_1 + c_2(-\wvec_1+\wvec_2)
	    = (c_1-c_2)\wvec_1 + c_2\wvec_2\text{,}
	  </me>
	  a linear combination of <m>\wvec_1</m> and <m>\wvec_2</m>.
	  This tells us that
	  <me>
	    W_2 = \laspan{\wvec_1,\wvec_2} = 
	    \laspan{\vvec_1,\vvec_2}\text{.}
	  </me>
	  In other words, <m>\wvec_1</m> and <m>\wvec_2</m> is a
	  orthogonal basis for <m>W_2</m>,  the 2-dimensional subspace
	  that is the span of <m>\vvec_1</m> and
	  <m>\vvec_2</m>.
	</p>

	<p>
	  Finally, we form <m>\wvec_3</m> from <m>\vvec_3</m> by
	  subtracting its orthogonal projection onto <m>W_2</m>:
	  <me>
	    \wvec_3 = \vvec_3 -
	    \frac{\vvec_3\cdot\wvec_1}{\wvec_1\cdot\wvec_1}\wvec_1 -
	    \frac{\vvec_3\cdot\wvec_2}{\wvec_2\cdot\wvec_2}\wvec_2
	    = \vvec_3 + \wvec_1 - 2\wvec_2
	    = \threevec22{-1}\text{.}
	  </me>
	</p>

	<p>
	  We can now check that
	  <me>
	    \wvec_1=\threevec2{-1}2,\hspace{24pt}
	    \wvec_2=\threevec{-1}22,\hspace{24pt}
	    \wvec_3=\threevec22{-1},\hspace{24pt}
	  </me>
	  is an orthogonal set.  Furthermore, we have,
	  as before, <m>\laspan{\wvec_1,\wvec_2,\wvec_3}
	  = \laspan{\vvec_1,\vvec_2,\vvec_3}</m>, which says that we
	  have found 
	  a new orthogonal basis for <m>\real^3</m>.
	</p>

	<p>
	  To create an orthonormal basis, we form unit vectors
	  parallel to each of the vectors in the orthogonal basis:
	  <me>
	    \uvec_1 = \threevec{2/3}{-1/3}{2/3},\hspace{24pt}
	    \uvec_2 = \threevec{-1/3}{2/3}{2/3},\hspace{24pt}
	    \uvec_3 = \threevec{2/3}{2/3}{-1/3}\text{.}
	  </me>
	</p>
      </statement>
    </example>

    <p>
      More generally, if we have a basis
      <m>\vvec_1,\vvec_2,\ldots,\vvec_n</m> for a subspace <m>W</m> of
      <m>\real^m</m>, the Gram-Schmidt algorithm creates an orthogonal
      basis for <m>W</m> in the following way:
      <md>
	<mrow>
	  \wvec_1 \amp = \vvec_1
	</mrow>
	<mrow>
	  \wvec_2 \amp = \vvec_2 -
	  \frac{\vvec_2\cdot\wvec_1}{\wvec_1\cdot\wvec_1}\wvec_1
	</mrow>
	<mrow>
	  \wvec_3 \amp = \vvec_3 -
	  \frac{\vvec_3\cdot\wvec_1}{\wvec_1\cdot\wvec_1}\wvec_1 -
	  \frac{\vvec_3\cdot\wvec_2}{\wvec_2\cdot\wvec_2}\wvec_2
	</mrow>
	<mrow>
	  \amp \vdots
	</mrow>
	<mrow>
	  \wvec_n \amp = \vvec_n -
	  \frac{\vvec_n\cdot\wvec_1}{\wvec_1\cdot\wvec_1}\wvec_1 -
	  \frac{\vvec_n\cdot\wvec_2}{\wvec_2\cdot\wvec_2}\wvec_2 -
	  \ldots - 
	  \frac{\vvec_n\cdot\wvec_{n-1}}
	  {\wvec_{n-1}\cdot\wvec_{n-1}}\wvec_{n-1}
	  \text{.} 
	</mrow>
      </md>
    </p>

    <p>
      From here, we may form an orthonormal basis by constructing a
      unit vector parallel to each vector in the orthogonal basis:
      <m>\uvec_j = 1/\len{\wvec_j}~\wvec_j</m>.
    </p>

    <activity>
      <statement>
	<p>
	  Sage can automate these computations for us.  Before
	  we begin, however, it will be helpful to understand how we can
	  combine things using a <c>list</c> in Python.  For
	  instance, if the vectors <c>v1</c>, <c>v2</c>, and <c>v3</c>
	  form a basis for a subspace, we can bundle them together using
	  square brackets: <c>[v1, v2, v3]</c>.  Furthermore, we could
	  assign this to a variable, such as <c>basis = [v1, v2, v3]</c>.
	</p>
	
	<p>
	  Evaluating the following cell will load in some special
	  commands.  
	  <sage>
	    <input>
sage.repl.load.load("https://raw.githubusercontent.com/davidaustinm/ula_modules/master/orthogonality.py", globals())
	    </input>
	  </sage>
	  <ul>
	    <li>
	      <p>
		There is a command to apply the projection formula:
		<c>projection(b, basis)</c> returns the orthogonal
		projection of <c>b</c> onto the subspace spanned by
		<c>basis</c>, which is a list of vectors.
	      </p>
	    </li>
	    <li>
	      <p>
		The command <c>unit(w)</c> returns a unit vector
		parallel to <c>w</c>.
	      </p>
	    </li>
	    <li>
	      <p>
		Given a collection of vectors, say, <c>v1</c> and
		<c>v2</c>, we can form the matrix whose columns are
		<c>v1</c> and <c>v2</c> using
		<c>matrix([v1, v2]).T</c>.  When given a <c>list</c> of
		vectors, Sage constructs a matrix whose <em>rows</em>
		are the given vectors.  For this reason, we need to apply
		the transpose.
	      </p>
	    </li>
	  </ul>
	</p>

	<p>
	  Let's now consider <m>W</m>, the subspace of <m>\real^5</m>
	  having basis
	  <me>
	    \vvec_1 = \fivevec{14}{-6}{8}2{-6},\hspace{24pt}
	    \vvec_2 = \fivevec{5}{-3}{4}3{-7},\hspace{24pt}
	    \vvec_3 = \fivevec{2}30{-2}1.
	  </me>
	  
	  <ol marker="a.">
	    <li>
	      <p>
		Apply the Gram-Schmidt algorithm to find an orthogonal
		basis <m>\wvec_1</m>, <m>\wvec_2</m>, and <m>\wvec_3</m>
		for <m>W</m>.
	      </p>
	      <sage>
		<input>
		</input>
	      </sage>
	    </li>

	    <li>
	      <p>
		Find <m>\bhat</m>,
		the orthogonal projection of <m>\bvec = 
		\fivevec{-5}{11}0{-1}5</m> onto <m>W</m>.
	      </p>
	    </li>

	    <li>
	      <p>
		Explain why we know that <m>\bhat</m> is a linear
		combination of the 
		original vectors <m>\vvec_1</m>, <m>\vvec_2</m>, and
		<m>\vvec_3</m> and then find weights so that
		<me>
		  \bhat = c_1\vvec_1 + c_2\vvec_2 + c_3\vvec_3.
		</me>
	      </p>
	    </li>

	    <li>
	      <p>
		Find an orthonormal basis <m>\uvec_1</m>,
		<m>\uvec_2</m>, for <m>\uvec_3</m> for <m>W</m> and form
		the matrix <m>Q</m> whose columns are these vectors.
	      </p>
	      <sage>
		<input>
		</input>
	      </sage>
	    </li>

	    <li>
	      <p>
		Find the product <m>Q^TQ</m> and explain the result.
	      </p>
	    </li>

	    <li>
	      <p>
		Find the matrix <m>P</m> that projects vectors
		orthogonally onto <m>W</m> and verify that <m>P\bvec</m>
		gives <m>\bhat</m>, the orthogonal projection that you
		found earlier.
	      </p>
	    </li>

	  </ol>
	</p>
      </statement>

      <solution>
	<p>
	  <ol marker="a.">
	    <li>
	      <p>
		<me>
		  \wvec_1=\fivevec{14}{-6}82{-6},\hspace{24pt}
		  \wvec_2=\fivevec{-2}{0}02{-4},\hspace{24pt}
		  \wvec_3=\fivevec130{-1}{-1}
		</me>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\bhat=\fivevec{-4}9{-4}{-4}3</m>
	      </p>
	    </li>
	    <li>
	      <p>
		We know that <m>\bhat</m> is in <m>W</m> and
		<m>\vvec_1</m>, <m>\vvec_2</m>, and <m>\vvec_3</m> is
		a basis for <m>W</m>.  We find
		<m>\bhat=-\frac34\vvec_1+\frac12\vvec_2+2\vvec_3</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<me>
		  \uvec_1=\fivevec{14/\sqrt{336}}{-6\sqrt{336}}{8/\sqrt{336}}
		  {2/\sqrt{336}}{-6/\sqrt{336}},\hspace{24pt}
		  \uvec_2=\fivevec{-2/\sqrt{24}}{0}0{2/\sqrt{24}}{-4/\sqrt{24}},\hspace{24pt}
		  \uvec_3=\fivevec{1/\sqrt{12}}{3/\sqrt{12}}0{-1/\sqrt{12}}{-1/\sqrt{12}}
		</me>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>Q^TQ=I</m> since the matrix product computes the
		dot products of the columns of <m>Q</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>P = QQ^T = \begin{bmatrix}
		5/6 \amp 0 \amp 1/3 \amp -1/6 \amp 0 \\
		0 \amp 6/7 \amp -1/7 \amp -2/7 \amp -1/7 \\
		1/3 \amp -1/7 \amp 4/21 \amp 1/21 \amp -1/7 \\
		-1/6 \amp -2/7 \amp 1/21 \amp 11/42 \amp -2/7 \\
		0 \amp -1/7 \amp -1/7 \amp -2/7 \amp 6/7
		\end{bmatrix}
		</m>
	      </p>
	    </li>
	  </ol>
	</p>
      </solution>
		
      <answer>
	<p>
	  <ol marker="a.">
	    <li>
	      <p>
		<me>
		  \wvec_1=\fivevec{14}{-6}82{-6},\hspace{24pt}
		  \wvec_2=\fivevec{-2}{0}02{-4},\hspace{24pt}
		  \wvec_3=\fivevec130{-1}{-1}
		</me>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\bhat=\fivevec{-4}9{-4}{-4}3</m>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\bhat=-\frac34\vvec_1+\frac12\vvec_2+2\vvec_3</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<me>
		  \uvec_1=\fivevec{14/\sqrt{336}}{-6\sqrt{336}}{8/\sqrt{336}}
		  {2/\sqrt{336}}{-6/\sqrt{336}},\hspace{24pt}
		  \uvec_2=\fivevec{-2/\sqrt{24}}{0}0{2/\sqrt{24}}
		  {-4/\sqrt{24}},\hspace{24pt}
		  \uvec_3=\fivevec{1/\sqrt{12}}{3/\sqrt{12}}0
		  {-1/\sqrt{12}}{-1/\sqrt{12}}
		</me>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>Q^TQ=I</m>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>P = QQ^T = \begin{bmatrix}
		5/6 \amp 0 \amp 1/3 \amp -1/6 \amp 0 \\
		0 \amp 6/7 \amp -1/7 \amp -2/7 \amp -1/7 \\
		1/3 \amp -1/7 \amp 4/21 \amp 1/21 \amp -1/7 \\
		-1/6 \amp -2/7 \amp 1/21 \amp 11/42 \amp -2/7 \\
		0 \amp -1/7 \amp -1/7 \amp -2/7 \amp 6/7
		\end{bmatrix}
		</m>
	      </p>
	    </li>
	  </ol>
	</p>
      </answer>
		
    </activity>

  </subsection>

  <subsection>
    <title> <m>QR</m> factorizations </title>

    <p>
      Now that we've seen how the Gram-Schmidt algorithm forms an
      orthonormal basis for a given subspace, we will explore how the
      algorithm leads to an important matrix factorization known as
      the <m>QR</m> factorization.
    </p>

    <activity>
      <statement>
	<p>
	  Suppose that <m>A</m> is the <m>4\times3</m> matrix whose
	  columns are
	  <me>
	    \vvec_1 = \fourvec1111,\hspace{24pt}
	    \vvec_2 = \fourvec1322,\hspace{24pt}
	    \vvec_3 = \fourvec1{-3}{-3}{-3}\text{.}
	  </me>
	  These vectors form a basis for <m>W</m>, the subspace of
	  <m>\real^4</m> that we encountered in <xref
	  ref="activity-gram-schmidt" />.  Since these vectors are the
	  columns of <m>A</m>, we have <m>\col(A) = W</m>.
	  <sage>
	    <input>
	    </input>
	  </sage>
	  <ol marker="a.">
	    <li>
	      <p>
		When we implemented Gram-Schmidt, we first found an
		orthogonal basis <m>\wvec_1</m>, <m>\wvec_2</m>, and
		<m>\wvec_3</m> using
		<me>
		  \begin{aligned}
		  \wvec_1 \amp = \vvec_1 \\
		  \wvec_2 \amp = \vvec_2 -
		  \frac{\vvec_2\cdot\wvec_1}{\wvec_1\cdot\wvec_1}\wvec_1 \\
		  \wvec_3 \amp = \vvec_3 -
		  \frac{\vvec_3\cdot\wvec_1}{\wvec_1\cdot\wvec_1}\wvec_1 -
		  \frac{\vvec_3\cdot\wvec_2}{\wvec_2\cdot\wvec_2}\wvec_2\text{.}
		  \\
		  \end{aligned}
		</me>
		Use these expressions to write <m>\vvec_1</m>,
		<m>\vvec_2</m>, and 
		<m>\vvec_3</m> as linear combinations of <m>\wvec_1</m>,
		<m>\wvec_2</m>, and <m>\wvec_3</m>.
	      </p>
	    </li>

	    <li>
	      <p>
		We next normalized the orthogonal basis
		<m>\wvec_1</m>, <m>\wvec_2</m>, and <m>\wvec_3</m> to obtain
		an orthonormal basis <m>\uvec_1</m>, <m>\uvec_2</m>, and
		<m>\uvec_3</m>.
	      </p>

	      <p>
		Write the vectors <m>\wvec_i</m> as scalar multiples of
		<m>\uvec_i</m>.
		Then use these expressions to write
		<m>\vvec_1</m>, <m>\vvec_2</m>, and
		<m>\vvec_3</m> as linear combinations of <m>\uvec_1</m>,
		<m>\uvec_2</m>, and <m>\uvec_3</m>.
	      </p>
	    </li>
	    
	    <li>
	      <p>
		Suppose that
		<m>Q =
		\left[
		\begin{array}{ccc}
		\uvec_1 \amp \uvec_2 \amp \uvec_3
		\end{array}
		\right]</m>.  Use the result of the previous part to find a
		vector <m>\rvec_1</m> so that <m>Q\rvec_1 = \vvec_1</m>.
	      </p>
	    </li>

	    <li>
	      <p>
		Then find vectors <m>\rvec_2</m> and <m>\rvec_3</m>
		such that <m>Q\rvec_2 = \vvec_2</m> and <m>Q\rvec_3 =
		\vvec_3</m>.
	      </p>
	    </li>

	    <li>
	      <p>
		Construct the matrix
		<m>R =
		\left[
		\begin{array}{ccc}
		\rvec_1 \amp \rvec_2 \amp \rvec_3
		\end{array}
		\right]</m>.  Remembering that
		<m>A =
		\left[
		\begin{array}{ccc}
		\vvec_1 \amp \vvec_2 \amp \vvec_3
		\end{array}
		\right]</m>, explain why <m>A = QR</m>.
	      </p>
	    </li>

	    <li>
	      <p>
		What is special about the shape of <m>R</m>?
	      </p>
	    </li>

	    <li>
	      <p>
		Suppose that <m>A</m> is a <m>10\times 6</m> matrix
		whose columns are linearly independent.  This means that
		the columns of <m>A</m> form a basis for
		<m>W=\col(A)</m>, a 6-dimensional subspace of
		<m>\real^{10}</m>.  Suppose that we apply Gram-Schmidt
		orthogonalization to create an orthonormal basis whose
		vectors form the columns of <m>Q</m> and that we write
		<m>A=QR</m>.  What are the shape of <m>Q</m> and
		what the shape of <m>R</m>?
	      </p>
	    </li>

	  </ol>
	</p>
      </statement>

      <solution>
	<p>
	  <ol marker="a.">
	    <li>
	      <p>
		<me>
		  \begin{aligned}
		  \wvec_1 \amp = \vvec_1 \\
		  \wvec_2 \amp = \vvec_2 - 2\wvec_1 \\
		  \wvec_3 \amp = \vvec_3 + 2\wvec_1 + 2\wvec_2 \\
		  \end{aligned}
		</me>
		Therefore,
		<me>
		  \begin{aligned}
		  \vvec_1 \amp = \wvec_1 \\
		  \vvec_2 \amp = 2\wvec_1 + \wvec_2 \\
		  \vvec_3 \amp = -2\wvec_1 - 2\wvec_2 + \wvec_3 \\
		  \end{aligned}
		</me>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\wvec_i = \len{\wvec_i}\uvec_i</m> so we have
		<me>
		  \wvec_1 = 2\uvec_1,\hspace{24pt}
		  \wvec_1 = \sqrt{2}\uvec_2,\hspace{24pt}
		  \wvec_1 = 2\uvec_3\text{.}
		</me>
		This leads to
		<me>
		  \begin{aligned}
		  \vvec_1 \amp = 2\uvec_1 \\
		  \vvec_2 \amp = 4\uvec_1 + \sqrt{2}\uvec_2 \\
		  \vvec_3 \amp = -4\uvec_1 - 2\sqrt{2}\uvec_2 + 2\uvec_3 \\
		  \end{aligned}
		</me>
	      </p>
	    </li>
	    <li>
	      <p>
		Since <m>\vvec_1 = 2\uvec_1</m>, we have <m>\vvec_1 =
		Q\threevec{2}00</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		In the same way, we have <m>\vvec_2 =
		Q\threevec4{\sqrt{2}}0</m> and
		<m>\vvec_3=Q\threevec{-4}{-2\sqrt{2}}2</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		We have <m>QR = \begin{bmatrix} Q\rvec_1 \amp Q\rvec_2
		\amp Q\rvec_3 \end{bmatrix} = A</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>R=\begin{bmatrix}
		2 \amp 4 \amp -4 \\
		0 \amp \sqrt{2} \amp -2\sqrt{2} \\
		0 \amp 0 \amp 2 \\
		\end{bmatrix}
		</m> so <m>R</m> is upper triangular.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>Q</m> will be <m>10\times6</m> and <m>R</m> will be a
		<m>6\times 6</m> upper triangular matrix.
	      </p>
	    </li>
	  </ol>
	</p>
      </solution>

      <answer>
	<p>
	  <ol marker="a.">
	    <li>
	      <p>
		<me>
		  \begin{aligned}
		  \vvec_1 \amp = \wvec_1 \\
		  \vvec_2 \amp = 2\wvec_1 + \wvec_2 \\
		  \vvec_3 \amp = -2\wvec_1 - 2\wvec_2 + \wvec_3 \\
		  \end{aligned}
		</me>
	      </p>
	    </li>
	    <li>
	      <p>
		<me>
		  \begin{aligned}
		  \vvec_1 \amp = 2\uvec_1 \\
		  \vvec_2 \amp = 4\uvec_1 + \sqrt{2}\uvec_2 \\
		  \vvec_3 \amp = -4\uvec_1 - 2\sqrt{2}\uvec_2 + 2\uvec_3 \\
		  \end{aligned}
		</me>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\vvec_1 =
		Q\threevec{2}00</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\vvec_2 =
		Q\threevec4{\sqrt{2}}0</m> and
		<m>\vvec_3=Q\threevec{-4}{-2\sqrt{2}}2</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		We have <m>QR = \begin{bmatrix} Q\rvec_1 \amp Q\rvec_2
		\amp Q\rvec_3 \end{bmatrix} = A</m>.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>R</m> is upper triangular.
	      </p>
	    </li>
	    <li>
	      <p>
		<m>Q</m> will be <m>10\times6</m> and <m>R</m> will be
		<m>6\times 6</m>.
	      </p>
	    </li>
	  </ol>
	</p>
      </answer>
		
    </activity>

    <p>
      When the columns of a matrix <m>A</m> are linearly independent,
      they form a basis for <m>\col(A)</m> so that we
      can perform the Gram-Schmidt algorithm.  The previous activity
      shows how this leads to a factorization of <m>A</m> as the
      product of a matrix <m>Q</m> whose columns are an orthonormal
      basis for <m>\col(A)</m> and an upper triangular matrix
      <m>R</m>. 
    </p>

    <proposition xml:id="prop-qr">
      <title> <m>QR</m> factorization </title>
      <statement>
	If <m>A</m> is an <m>m\times n</m> matrix whose columns are
	linearly independent, we may write
	<m>A=QR</m> where <m>Q</m> is an <m>m\times n</m> matrix whose
	columns form an orthonormal basis for <m>\col(A)</m> and
	<m>R</m> is an <m>n\times n</m> upper triangular matrix.
      </statement>
    </proposition>

    <example>
      <statement>
	<p>
	  We'll consider the matrix <m>A=\begin{bmatrix}
	  2 \amp -3 \amp -2 \\
	  -1 \amp 3 \amp 7 \\
	  2 \amp 0 \amp 1 \\
	  \end{bmatrix}</m>
	  whose columns, which we'll denote <m>\vvec_1</m>,
	  <m>\vvec_2</m>, and <m>\vvec_3</m>, are the basis of
	  <m>\real^3</m> that we 
	  considered in <xref ref="example-gram-schmidt" />.
	  There we found an orthogonal basis <m>\wvec_1</m>,
	  <m>\wvec_2</m>, and <m>\wvec_3</m> that satisfied
	  <md>
	    <mrow>
	      \vvec_1 \amp {}={} \wvec_1
	    </mrow>
	    <mrow>
	      \vvec_2 \amp {}={} -\wvec_1 + \wvec_2
	    </mrow>
	    <mrow>
	      \vvec_3 \amp {}={} -\wvec_1 + 2\wvec_2 + \wvec _3\text{.}
	    </mrow>
	  </md>
	</p>

	<p>
	  In terms of the resulting orthonormal basis <m>\uvec_1</m>,
	  <m>\uvec_2</m>, and <m>\uvec_3</m>, we had
	  <me>
	    \wvec_1 = 3 \uvec_1,\hspace{24pt}
	    \wvec_2 = 3 \uvec_2,\hspace{24pt}
	    \wvec_3 = 3 \uvec_3
	  </me>
	  so that
	  <md>
	    <mrow>
	      \vvec_1 \amp {}={} 3\uvec_1
	    </mrow>
	    <mrow>
	      \vvec_2 \amp {}={} -3\uvec_1 + 3\uvec_2
	    </mrow>
	    <mrow>
	      \vvec_3 \amp {}={} -3\uvec_1 + 6\uvec_2 + 3\uvec _3\text{.}
	    </mrow>
	  </md>
	</p>

	<p>
	  Therefore, if <m>Q=\begin{bmatrix} \uvec_1 \amp \uvec_2 \amp
	  \uvec_3 \end{bmatrix}</m>, we have the <m>QR</m> factorization
	  <me>
	    A = Q\begin{bmatrix}
	    3 \amp -3 \amp -3 \\
	    0 \amp 3 \amp 6 \\
	    0 \amp 0 \amp 3 \\
	    \end{bmatrix}
	    =QR\text{.}
	  </me>
	</p>
      </statement>
    </example>

    <p>
      The value of the <m>QR</m> factorization will become clear in
      the next section where we use it to solve least-squares
      problems.
    </p>

    <activity>
      <statement>
	<p>
	  As before, we would like to use Sage to automate the process
	  of finding and using the <m>QR</m> factorization of a matrix
	  <m>A</m>. 
	  Evaluating the following cell provides a command <c>QR(A)</c>
	  that returns the factorization, which may be stored using,
	  for example, 
	  <c>Q, R = QR(A)</c>.
	  <sage>
	    <input>
sage.repl.load.load("https://raw.githubusercontent.com/davidaustinm/ula_modules/master/orthogonality.py", globals())
	    </input>
	  </sage>
	</p>
	
	<p>
	  Suppose that <m>A</m> is the following matrix whose columns
	  are linearly independent.
	  <me>
	    A =
	    \begin{bmatrix}
	    1 \amp 0 \amp -3 \\
	    0 \amp 2 \amp -1 \\
	    1 \amp 0 \amp 1 \\
	    1 \amp 3 \amp 5 \\
	    \end{bmatrix}.
	  </me>
	  <ol marker="a.">
	    <li>
	      <p>
		If <m>A=QR</m>, what is the shape of <m>Q</m> and
		<m>R</m>?  What is special about the form of <m>R</m>?
	      </p>
	    </li>
	    
	    <li>
	      <p>
		Find the <m>QR</m> factorization using 
		<c>Q, R = QR(A)</c> and verify that <m>R</m> has the predicted
		shape and that <m>A=QR</m>.
		<sage>
		  <input>
		  </input>
		</sage>
	      </p>
	    </li>
	    
	    <li>
	      <p>
		Find the matrix <m>P</m> that orthogonally projects
		vectors onto <m>\col(A)</m>.
	      </p>
	    </li>
	    
	    <li>
	      <p>
		Find <m>\bhat</m>, the orthogonal projection of
		<m>\bvec=\fourvec4{-17}{-14}{22}</m> onto
		<m>\col(A)</m>.
	      </p>
	    </li>
	    
	    <li>
	      <p>
		Explain why the equation
		<m>A\xvec=\bhat</m> must be consistent and then find
		<m>\xvec</m>.
	      </p>
	    </li>
	  </ol>
	</p>
      </statement>

      <solution>
	<p>
	  <ol marker="a.">
	    <li>
	      <p>
		<m>Q</m> is <m>4\times3</m> and <m>R</m> is a
		<m>3\times3</m> upper triangular matrix.
	      </p>
	    </li>
	    <li>
	      <p>
		We see that
		<me>
		  Q=\begin{bmatrix}
		  1/\sqrt{3} \amp -1/\sqrt{10} \amp -3/\sqrt{23} \\
		  0 \amp 2/\sqrt{10} \amp -3/\sqrt{23} \\
		  1/\sqrt{3} \amp -1/\sqrt{10} \amp 1/\sqrt{23} \\
		  1/\sqrt{3} \amp 2/\sqrt{10} \amp 2/\sqrt{23} \\
		  \end{bmatrix},\hspace{24pt}
		  R = \begin{bmatrix}
		  \sqrt{3} \amp \sqrt{3} \amp \sqrt{3} \\
		  0 \amp \sqrt{10} \amp \sqrt{10} \\
		  0 \amp 0 \amp \sqrt{23}
		  \end{bmatrix}
		</me>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>P=QQ^T = \begin{bmatrix}
		569/690 \amp 22/115 \amp 209/690 \amp -44/345 \\
		22/115 \amp 91/115 \amp -38/115 \amp 16/115 \\
		209/690 \amp -38/115 \amp 329/690 \amp 76/345 \\
		-44/345 \amp 16/115 \amp 76/345 \amp 313/345 \\
		\end{bmatrix}
		</m>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\bhat = QQ^T\bvec = \fourvec{-7}{-5}5{14}</m>
	      </p>
	    </li>
	    <li>
	      <p>
		Since <m>\bhat</m> is in <m>\col(A)</m>, the system
		<m>A\xvec=\bhat</m> must be consistent.  We find a
		solution by augmenting <m>A</m> by <m>\bhat</m> and
		row reducing:  <m>\xvec = \threevec2{-1}3</m>.
	      </p>
	    </li>
	  </ol>
	</p>
      </solution>
	    
      <answer>
	<p>
	  <ol marker="a.">
	    <li>
	      <p>
		<m>Q</m> is <m>4\times3</m> and <m>R</m> is a
		<m>3\times3</m> upper triangular matrix.
	      </p>
	    </li>
	    <li>
	      <p>
		We see that
		<me>
		  Q=\begin{bmatrix}
		  1/\sqrt{3} \amp -1/\sqrt{10} \amp -3/\sqrt{23} \\
		  0 \amp 2/\sqrt{10} \amp -3/\sqrt{23} \\
		  1/\sqrt{3} \amp -1/\sqrt{10} \amp 1/\sqrt{23} \\
		  1/\sqrt{3} \amp 2/\sqrt{10} \amp 2/\sqrt{23} \\
		  \end{bmatrix},\hspace{24pt}
		  R = \begin{bmatrix}
		  \sqrt{3} \amp \sqrt{3} \amp \sqrt{3} \\
		  0 \amp \sqrt{10} \amp \sqrt{10} \\
		  0 \amp 0 \amp \sqrt{23}
		  \end{bmatrix}
		</me>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>P=QQ^T = \begin{bmatrix}
		569/690 \amp 22/115 \amp 209/690 \amp -44/345 \\
		22/115 \amp 91/115 \amp -38/115 \amp 16/115 \\
		209/690 \amp -38/115 \amp 329/690 \amp 76/345 \\
		-44/345 \amp 16/115 \amp 76/345 \amp 313/345 \\
		\end{bmatrix}
		</m>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\bhat = \fourvec{-7}{-5}5{14}</m>
	      </p>
	    </li>
	    <li>
	      <p>
		<m>\xvec = \threevec2{-1}3</m>.
	      </p>
	    </li>
	  </ol>
	</p>
      </answer>
	    
    </activity>

    <p>
      In fact, Sage provides its own version of the <m>QR</m>
      factorization that is a bit different than the way we've
      developed the factorization here.  For this reason, we have
      provided our own version of the factorization.
    </p>

  </subsection>

  <subsection>
    <title> Summary </title>

    <p>
      This section explored the Gram-Schmidt orthogonalization
      algorithm and how it leads to the matrix factorization
      <m>A=QR</m> when the columns of <m>A</m> are linearly
      independent.
      <ul>
	<li>
	  <p>
	    Beginning with a basis <m>\vvec_1,
	    \vvec_2,\ldots,\vvec_n</m> for a subspace <m>W</m>
	    of <m>\real^m</m>, the vectors
	    <md>
	      <mrow>
		\wvec_1 \amp = \vvec_1
	      </mrow>
	      <mrow>
		\wvec_2 \amp = \vvec_2 -
		\frac{\vvec_2\cdot\wvec_1}{\wvec_1\cdot\wvec_1}\wvec_1
	      </mrow>
	      <mrow>
		\wvec_3 \amp = \vvec_3 -
		\frac{\vvec_3\cdot\wvec_1}{\wvec_1\cdot\wvec_1}\wvec_1 -
		\frac{\vvec_3\cdot\wvec_2}{\wvec_2\cdot\wvec_2}\wvec_2
	      </mrow>
	      <mrow>
		\amp \vdots
	      </mrow>
	      <mrow>
		\wvec_n \amp = \vvec_n -
		\frac{\vvec_n\cdot\wvec_1}{\wvec_1\cdot\wvec_1}\wvec_1 -
		\frac{\vvec_n\cdot\wvec_2}{\wvec_2\cdot\wvec_2}\wvec_2 -
		\ldots - 
		\frac{\vvec_n\cdot\wvec_{n-1}}
		{\wvec_{n-1}\cdot\wvec_{n-1}}\wvec_{n-1}
	      </mrow>
	    </md>
	    form an orthogonal basis for <m>W</m>.
	  </p>
	</li>

	<li>
	  <p>
	    We may scale each vector <m>\wvec_i</m> appropriately to
	    obtain an orthonormal basis
	    <m>\uvec_1,\uvec_2,\ldots,\uvec_n</m>.
	  </p>
	</li>

	<li>
	  <p>
	    Expressing the Gram-Schmidt algorithm in matrix form shows
	    that, if the columns of <m>A</m> are linearly
	    independent, then we can write <m>A=QR</m>, where the
	    columns of <m>Q</m> form an orthonormal basis for
	    <m>\col(A)</m> and <m>R</m> is upper triangular.
	  </p>
	</li>
      </ul>
    </p>

  </subsection>

  <xi:include href="exercises/exercises6-4.xml" />
  
</section>

