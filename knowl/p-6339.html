<!DOCTYPE html>
<html lang="en-US" dir="ltr">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h3 class="heading"><span class="type">Paragraph</span></h3>
<div class="para logical">
<div class="para">The last section demonstrated the value of working with orthogonal, and especially orthonormal, sets.  If we have an orthogonal basis <span class="process-math">\(\wvec_1,\wvec_2,\ldots,\wvec_n\)</span> for a subspace <span class="process-math">\(W\text{,}\)</span> the <a href="" class="xref" data-knowl="./knowl/prop-proj-formula.html" title="Proposition 6.3.15: Projection formula">Projection FormulaÂ 6.3.15</a> tells us that the orthogonal projection of a vector <span class="process-math">\(\bvec\)</span> onto <span class="process-math">\(W\)</span> is</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/prop-proj-formula.html">
\begin{equation*}
\bhat =
\frac{\bvec\cdot\wvec_1}{\wvec_1\cdot\wvec_1}~\wvec_1 + 
\frac{\bvec\cdot\wvec_2}{\wvec_2\cdot\wvec_2}~\wvec_2 +
\cdots + 
\frac{\bvec\cdot\wvec_n}{\wvec_n\cdot\wvec_n}~\wvec_n\text{.}
\end{equation*}
</div>
<div class="para">An orthonormal basis <span class="process-math">\(\uvec_1,\uvec_2,\ldots,\uvec_n\)</span> is even more convenient:  after forming the matrix <span class="process-math">\(Q=\begin{bmatrix} \uvec_1 \amp \uvec_2 \amp \ldots \amp
\uvec_n
\end{bmatrix}\text{,}\)</span> we have <span class="process-math">\(\bhat = QQ^T\bvec\text{.}\)</span>
</div>
</div>
<span class="incontext"><a href="sec-gram-schmidt.html#p-6339" class="internal">in-context</a></span>
</body>
</html>
